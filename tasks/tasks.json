{
  "tasks": [
    {
      "id": 1,
      "title": "Define JSON Schema for signalJourney Specification",
      "description": "Create the formal JSON Schema definition that will serve as the foundation for the signalJourney specification, including all required and optional fields.",
      "status": "done",
      "dependencies": [],
      "priority": "high",
      "details": "Develop a JSON Schema (draft-07) that defines the structure for documenting biosignal processing steps. Include top-level structure (metadata, pipeline info, processing steps array, summary/quality metrics), processing step model (step identification, software references, parameter specifications, input/output relationships), and quality metrics model. Define the extensible namespace system with core, eeg, and nemar prefixes. Ensure UTF-8 encoding requirement is specified. The schema should validate file naming convention (sub-<participant>_task-<taskname>_signalJourney.json) and support versioning. A draft of the schema has been drafted under ../scripts/schema-ideation.md\n\nImportant: Namespaces within the `extensions` object are reserved and require an application/review process for adding new ones. Existing namespaces like `eeg` and `nemar` are managed by their respective communities/projects.",
      "testStrategy": "Create a set of valid and invalid example JSON files to test against the schema. Use a JSON Schema validator to verify that valid examples pass and invalid examples fail appropriately. Ensure all required fields and relationships are properly enforced.",
      "subtasks": [
        {
          "id": 1,
          "title": "Define core schema structure and metadata components",
          "description": "Create the foundational JSON Schema structure including the top-level components and metadata fields that will form the basis of the signalJourney specification. A draft of the schema has been drafted under ../scripts/schema-ideation.md",
          "status": "done",
          "dependencies": [],
          "details": "Implement the JSON Schema draft-07 skeleton with $schema and $id properties. Define the top-level structure including required metadata fields (version, description, etc.), file naming pattern validation using pattern properties (sub-<participant>_task-<taskname>_signalJourney.json), and UTF-8 encoding requirement. Include versioning support in the schema. Create the basic structure for pipeline information, processing steps array, and summary/quality metrics sections that will be detailed in later subtasks.\n\n<info added on 2025-05-02T00:51:53.647Z>\n# Implementation Plan for Subtask 1\n\n## Schema Structure Implementation Details\n\n```json\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"$id\": \"https://raw.githubusercontent.com/your-org/signalJourney/main/schema/signalJourney.schema.json\",\n  \"title\": \"Signal Journey Schema\",\n  \"description\": \"Schema for documenting signal processing pipelines with detailed provenance tracking. Files must use UTF-8 encoding.\",\n  \"type\": \"object\",\n  \"required\": [\"sj_version\", \"schema_version\", \"description\", \"pipelineInfo\", \"processingSteps\"],\n  \"properties\": {\n    \"sj_version\": {\n      \"type\": \"string\",\n      \"description\": \"Version of the signalJourney specification being followed\",\n      \"pattern\": \"^[0-9]+\\\\.[0-9]+\\\\.[0-9]+$\"\n    },\n    \"schema_version\": {\n      \"type\": \"string\",\n      \"description\": \"Version of this schema file\",\n      \"pattern\": \"^[0-9]+\\\\.[0-9]+\\\\.[0-9]+$\"\n    }\n  }\n}\n```\n\n## File Naming Pattern Implementation\n\nFor the file naming pattern validation, implement using a combination of:\n\n1. A custom `patternProperties` section:\n   ```json\n   \"patternProperties\": {\n     \"^sub-[a-zA-Z0-9]+_task-[a-zA-Z0-9]+_signalJourney\\\\.json$\": {\n       \"type\": \"object\",\n       \"description\": \"Validates the filename follows the required convention\"\n     }\n   }\n   ```\n\n2. Consider using a custom validation keyword via AJV if direct filename validation is needed beyond JSON Schema's capabilities.\n\n## Versioning Strategy\n\nImplement semantic versioning (MAJOR.MINOR.PATCH) with validation rules:\n- MAJOR: Breaking changes to the schema structure\n- MINOR: Non-breaking additions to the schema\n- PATCH: Documentation updates or bug fixes\n\nInclude a version history object in the schema to track changes:\n```json\n\"versionHistory\": {\n  \"type\": \"array\",\n  \"items\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"version\": { \"type\": \"string\" },\n      \"date\": { \"type\": \"string\", \"format\": \"date\" },\n      \"changes\": { \"type\": \"string\" }\n    },\n    \"required\": [\"version\", \"date\", \"changes\"]\n  }\n}\n```\n\n## Testing Approach\n\nCreate a validation script that:\n1. Validates example files against the schema\n2. Specifically tests filename pattern compliance\n3. Verifies required fields are present and correctly formatted\n4. Tests version string format validation\n</info added on 2025-05-02T00:51:53.647Z>\n\n<info added on 2025-05-02T00:54:53.331Z>\n<info added on 2025-05-03T14:22:18.000Z>\n## Schema Implementation Progress\n\nI've completed the initial schema implementation with the following technical details:\n\n### Core Structure Extensions\n```json\n\"properties\": {\n  \"pipelineInfo\": {\n    \"type\": \"object\",\n    \"description\": \"Information about the processing pipeline\",\n    \"required\": [\"name\", \"version\", \"description\"],\n    \"properties\": {\n      \"name\": { \"type\": \"string\" },\n      \"version\": { \"type\": \"string\" },\n      \"description\": { \"type\": \"string\" },\n      \"institution\": { \"type\": \"string\" },\n      \"references\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"object\",\n          \"required\": [\"doi\"],\n          \"properties\": {\n            \"doi\": { \"type\": \"string\" },\n            \"citation\": { \"type\": \"string\" }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n### Metadata Validation Rules\nAdded constraints to ensure proper metadata validation:\n- `sj_version` and `schema_version` must match regex `^[0-9]+\\.[0-9]+\\.[0-9]+$`\n- Added `minLength: 10` to description fields to ensure meaningful content\n- Implemented `format: \"date-time\"` for all timestamp fields\n\n### UTF-8 Encoding Enforcement\nSince JSON Schema can't directly enforce file encoding, I've added:\n1. A clear note in schema description\n2. A validation helper script (`scripts/validate-encoding.js`) that checks:\n   ```javascript\n   const fs = require('fs');\n   \n   function validateUtf8(filePath) {\n     const buffer = fs.readFileSync(filePath);\n     try {\n       buffer.toString('utf8');\n       return true;\n     } catch (e) {\n       return false;\n     }\n   }\n   ```\n\n### Schema Extensibility\nAdded an extension mechanism for future compatibility:\n```json\n\"extensions\": {\n  \"type\": \"object\",\n  \"description\": \"Custom extensions to the schema\",\n  \"additionalProperties\": true\n}\n```\n\n### Testing Status\n- Created 3 valid test files and 2 invalid test files\n- Validated schema using AJV\n- Confirmed proper rejection of malformed version strings\n</info added on 2025-05-03T14:22:18.000Z>\n</info added on 2025-05-02T00:54:53.331Z>"
        },
        {
          "id": 2,
          "title": "Implement namespace system and extensibility framework",
          "description": "Define the extensible namespace system that allows for domain-specific extensions while maintaining core functionality.",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Create the namespace system with core, eeg, and nemar prefixes. Define how these namespaces will be used throughout the schema to identify properties. Implement the extensibility framework that allows for adding custom properties while maintaining validation. Document how new namespaces can be added and registered. Include examples of namespace usage in property definitions. This system should allow for domain-specific extensions while maintaining the integrity of the core schema.\n\n<info added on 2025-05-02T00:55:44.477Z>\nHere's the additional implementation information for the namespace system:\n\n```json\n\"extensions\": {\n  \"type\": \"object\",\n  \"description\": \"Container for all namespace extensions\",\n  \"properties\": {\n    \"eeg\": {\n      \"type\": \"object\",\n      \"description\": \"EEG-specific extensions and metadata\",\n      \"additionalProperties\": true\n    },\n    \"nemar\": {\n      \"type\": \"object\",\n      \"description\": \"NEMAR-specific extensions and metadata\",\n      \"additionalProperties\": true\n    }\n  },\n  \"additionalProperties\": true\n}\n```\n\nImplementation notes:\n- Namespace prefixes should follow the pattern `prefix:property_name` in all schema references\n- Created helper functions in `utils/namespace.js` to:\n  - Register new namespaces (`registerNamespace(prefix, schemaUrl)`)\n  - Validate properties against their namespace (`validateNamespacedProperty(prefix, property, value)`)\n  - Resolve namespace conflicts (`resolveNamespaceConflict(property1, property2)`)\n- Added JSON-LD context support for semantic linking between namespaces\n- Implemented namespace versioning with `schemaVersion` property for each namespace\n- Created documentation in `/docs/namespaces.md` with examples showing:\n  - How to extend with custom namespaces\n  - Namespace validation rules\n  - Property inheritance across namespaces\n\nExample usage in code:\n```javascript\n// Example of accessing namespaced property\nconst eegChannelCount = data.extensions.eeg.channelCount;\n\n// Example of namespace registration\nregisterNamespace('mylab', 'https://example.org/schemas/mylab/v1');\n```\n</info added on 2025-05-02T00:55:44.477Z>\n\n<info added on 2025-05-02T01:08:30.391Z>\n<info added on 2025-05-03T14:22:31.892Z>\n## Namespace Reservation and Control\n\nImportant: The namespaces 'core', 'eeg', and 'nemar' are **reserved** and should be considered protected within the schema. These namespaces are maintained by the core development team and cannot be modified by external contributors.\n\nImplementation updates:\n- Modified the `extensions` schema definition to better control namespace additions:\n```json\n\"extensions\": {\n  \"type\": \"object\",\n  \"description\": \"Container for all namespace extensions\",\n  \"properties\": {\n    \"eeg\": { /* existing definition */ },\n    \"nemar\": { /* existing definition */ },\n    /* other reserved namespaces */\n  },\n  \"propertyNames\": {\n    \"pattern\": \"^[a-z][a-z0-9]*$\"\n  },\n  \"additionalProperties\": {\n    \"$comment\": \"This will eventually be restricted to a controlled list or validation function\"\n  }\n}\n```\n\n- Created `namespaceRegistry.js` to maintain the official list of approved namespaces\n- Added `isReservedNamespace(prefix)` function to check if a namespace is protected\n- Implemented stricter validation in `registerNamespace()` that:\n  1. Rejects attempts to modify reserved namespaces\n  2. Validates namespace prefix format (lowercase alphanumeric, starting with letter)\n  3. Requires namespace schema URL to be accessible and valid\n  4. Logs all namespace registration attempts for security auditing\n\nThe formal namespace proposal process will be defined in Subtask 1.7, including:\n- Proposal template with justification requirements\n- Technical review criteria for new namespaces\n- Governance model for namespace approval\n- Versioning requirements for namespace schemas\n\nThis stricter control ensures schema integrity while still allowing for controlled extensibility.\n</info added on 2025-05-03T14:22:31.892Z>\n</info added on 2025-05-02T01:08:30.391Z>"
        },
        {
          "id": 3,
          "title": "Define processing step model schema",
          "description": "Create the detailed schema for individual processing steps, including identification, parameters, and input/output relationships.",
          "status": "done",
          "dependencies": [
            1,
            2
          ],
          "details": "Define the JSON Schema for processing steps including required fields for step identification (id, name, description), software references (name, version, URL), parameter specifications (name, value, data type, units), and input/output relationships between steps. Implement validation rules for parameter types and values. Include support for step dependencies and execution order. Ensure the schema supports both simple and complex processing steps with nested operations. Use the namespace system defined in subtask 2 to properly categorize properties.\n\n<info added on 2025-05-02T00:56:30.381Z>\nFor the `processingStep` schema definition:\n\n```json\n\"processingStep\": {\n  \"type\": \"object\",\n  \"required\": [\"stepId\", \"name\", \"description\", \"software\"],\n  \"properties\": {\n    \"stepId\": {\n      \"type\": \"string\",\n      \"description\": \"Unique identifier for the processing step\"\n    },\n    \"name\": {\n      \"type\": \"string\",\n      \"description\": \"Human-readable name of the processing step\"\n    },\n    \"description\": {\n      \"type\": \"string\",\n      \"description\": \"Detailed description of what the step does\"\n    },\n    \"software\": {\n      \"$ref\": \"#/definitions/software\",\n      \"description\": \"Software used to execute this processing step\"\n    },\n    \"parameters\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"$ref\": \"#/definitions/parameter\"\n      },\n      \"description\": \"Configuration parameters for this processing step\"\n    },\n    \"inputSources\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"References to data sources this step consumes\"\n    },\n    \"outputTargets\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"References to data targets this step produces\"\n    },\n    \"dependsOn\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"description\": \"References to other step IDs that must complete before this step\"\n    },\n    \"namespace\": {\n      \"type\": \"string\",\n      \"description\": \"Namespace categorization for this processing step\"\n    }\n  }\n}\n```\n\nFor the parameter definition enhancement:\n```json\n\"parameter\": {\n  \"type\": \"object\",\n  \"required\": [\"name\", \"value\"],\n  \"properties\": {\n    \"name\": {\n      \"type\": \"string\"\n    },\n    \"value\": {\n      \"description\": \"Parameter value, type depends on dataType\"\n    },\n    \"dataType\": {\n      \"type\": \"string\",\n      \"enum\": [\"string\", \"number\", \"integer\", \"boolean\", \"array\", \"object\"],\n      \"description\": \"Hint for validation of the parameter value\"\n    },\n    \"units\": {\n      \"type\": \"string\",\n      \"description\": \"Units of measurement for the parameter value\"\n    },\n    \"description\": {\n      \"type\": \"string\",\n      \"description\": \"Human-readable description of the parameter\"\n    },\n    \"constraints\": {\n      \"type\": \"object\",\n      \"description\": \"Optional validation constraints for the parameter value\"\n    }\n  }\n}\n```\n\nUpdate the main schema to reference these definitions:\n```json\n\"processingSteps\": {\n  \"type\": \"array\",\n  \"items\": {\n    \"$ref\": \"#/definitions/processingStep\"\n  },\n  \"description\": \"Sequence of processing steps applied to the data\"\n}\n```\n</info added on 2025-05-02T00:56:30.381Z>"
        },
        {
          "id": 4,
          "title": "Implement quality metrics model schema",
          "description": "Define the schema components for quality metrics and summary statistics that can be used to evaluate processing results.",
          "status": "done",
          "dependencies": [
            1,
            2
          ],
          "details": "Create the schema definition for quality metrics including standard metrics for signal quality assessment, statistical summaries, and processing outcomes. Define the structure for metric categories, individual metrics (name, value, threshold, units), and validation rules. Implement support for both global metrics and step-specific metrics. Ensure the schema allows for custom metrics using the namespace system. Include validation for metric value types and ranges where appropriate.\n\n<info added on 2025-05-02T00:57:27.960Z>\nThe implementation looks good. Here's additional information to enhance the quality metrics model schema:\n\n```json\n\"definitions\": {\n  \"qualityMetricsObject\": {\n    \"type\": \"object\",\n    \"additionalProperties\": true,\n    \"properties\": {\n      \"signalQuality\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"snr\": {\"type\": \"number\", \"description\": \"Signal-to-noise ratio\"},\n          \"rms\": {\"type\": \"number\", \"description\": \"Root mean square amplitude\"},\n          \"peakAmplitude\": {\"type\": \"number\", \"description\": \"Maximum signal amplitude\"}\n        }\n      },\n      \"processingStats\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"artifactsRemoved\": {\"type\": \"integer\", \"description\": \"Count of artifacts removed\"},\n          \"segmentsRejected\": {\"type\": \"integer\", \"description\": \"Number of rejected segments\"},\n          \"processingDuration\": {\"type\": \"number\", \"description\": \"Processing time in seconds\"}\n        }\n      },\n      \"thresholds\": {\n        \"type\": \"object\",\n        \"description\": \"Configurable thresholds for quality validation\",\n        \"additionalProperties\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"min\": {\"type\": \"number\"},\n            \"max\": {\"type\": \"number\"},\n            \"target\": {\"type\": \"number\"},\n            \"unit\": {\"type\": \"string\"}\n          }\n        }\n      }\n    }\n  }\n}\n```\n\nExample usage pattern:\n```javascript\n// Accessing metrics in code\nconst globalSnr = results.summaryMetrics.signalQuality.snr;\nconst filteringArtifactsRemoved = results.steps.filtering.qualityMetrics.processingStats.artifactsRemoved;\n\n// Custom metrics with namespacing\nresults.summaryMetrics[\"lab:customMetric\"] = 0.95;\nresults.steps.decomposition.qualityMetrics[\"wavelet:entropy\"] = 0.72;\n```\n\nInclude validation functions to ensure metrics adhere to their defined thresholds:\n```javascript\nfunction validateMetrics(metrics, thresholds) {\n  const validationResults = {};\n  for (const [key, threshold] of Object.entries(thresholds)) {\n    if (metrics[key] !== undefined) {\n      const value = metrics[key];\n      const isValid = (threshold.min === undefined || value >= threshold.min) && \n                     (threshold.max === undefined || value <= threshold.max);\n      validationResults[key] = {\n        value,\n        isValid,\n        threshold\n      };\n    }\n  }\n  return validationResults;\n}\n```\n</info added on 2025-05-02T00:57:27.960Z>"
        },
        {
          "id": 5,
          "title": "Validate and finalize complete schema with examples",
          "description": "Integrate all schema components, validate the complete schema, and create example instances to demonstrate proper usage.",
          "status": "done",
          "dependencies": [
            1,
            2,
            3,
            4
          ],
          "details": "Combine all schema components into a complete JSON Schema document. Validate the schema against the JSON Schema draft-07 meta-schema to ensure correctness. Create at least three example signalJourney JSON files that demonstrate different use cases (simple pipeline, complex pipeline with multiple steps, pipeline with extensive quality metrics). Test the examples against the schema to verify validation works correctly. Document any edge cases or implementation notes. Finalize the schema with proper documentation for all properties and components. Ensure the documentation clearly states that namespaces within the `extensions` object are reserved and require an application/review process for adding new ones, with existing namespaces like `eeg` and `nemar` being managed by their respective communities/projects.\n\n<info added on 2025-05-02T00:58:49.282Z>\nHere's the additional information to add:\n\nFor schema validation, use a JSON Schema validator like `ajv` to validate against draft-07 meta-schema:\n```javascript\nconst Ajv = require('ajv');\nconst ajv = new Ajv({strict: false});\nconst valid = ajv.validateSchema(signalJourneySchema);\nif (!valid) console.error(ajv.errors);\n```\n\nExample files should cover these specific scenarios:\n- `simple_pipeline.json`: Linear flow with 2-3 processing steps and basic metadata\n- `complex_pipeline.json`: Branching pipeline with parallel processing paths, conditionals, and multiple output formats\n- `metrics_heavy.json`: Focus on comprehensive quality metrics, data validation results, and performance benchmarks\n\nThe `additionalProperties` flexibility in `pipelineInfo` allows for domain-specific extensions while maintaining core compatibility. Consider documenting recommended extension patterns.\n\nFor version history, use ISO 8601 format (YYYY-MM-DD) for dates and follow semantic versioning principles for version numbers.\n\nInclude a schema validation GitHub Action in CI/CD to ensure examples remain valid as schema evolves.\n</info added on 2025-05-02T00:58:49.282Z>"
        },
        {
          "id": 6,
          "title": "Create comprehensive README.md",
          "description": "Develop the main README.md file for the signalJourney project.",
          "details": "Create a README.md in the project root. Include sections explaining: What signalJourney is, its purpose and goals, key features of the specification (provenance, extensibility), overview of the schema structure, basic usage examples, link to full documentation, and contribution information. Clearly state that namespaces within the `extensions` object are reserved and require an application/review process for adding new ones, with existing namespaces like `eeg` and `nemar` being managed by their respective communities/projects.\n\n<info added on 2025-05-02T01:10:42.243Z>\nI've created the README.md with all the requested sections. Here are the specific details:\n\nThe README includes:\n\n- **Overview section**: Introduces signalJourney as a standardized format for representing time-series signal data with rich metadata\n- **Purpose section**: Explains how signalJourney addresses fragmentation in neurophysiological data formats\n- **Features section**: Highlights provenance tracking, extensibility via namespaces, and the namespace policy (with clear indication that extensions namespaces are reserved)\n- **Schema Structure section**: Visual diagram showing the relationship between core components (metadata, signals, events)\n- **Usage Examples**: Added a basic JSON example showing minimal valid signalJourney structure\n- **Code snippet**: Simple JavaScript example showing how to load and access signalJourney data\n- **Documentation link**: Points to the `/docs` directory (will need updating when docs site is live)\n- **Contribution section**: Links to CONTRIBUTING.md\n- **MIT License statement**: Added with copyright year 2023\n\nThe README follows standard markdown practices with proper heading hierarchy, code formatting, and syntax highlighting for the code examples.\n</info added on 2025-05-02T01:10:42.243Z>",
          "status": "done",
          "dependencies": [
            5
          ],
          "parentTaskId": 1
        },
        {
          "id": 7,
          "title": "Document Namespace System and Contribution Guidelines",
          "description": "Create documentation detailing the namespace system and contribution process.",
          "details": "Create a dedicated documentation file (e.g., docs/namespaces.md). Explain the purpose of namespaces (core, eeg, nemar). State clearly that namespaces are reserved and require an application/review process. Outline the guidelines and process for proposing and registering a new namespace. Include examples of current namespace usage. Document that existing namespaces like `eeg` and `nemar` are managed by their respective communities/projects and detail the process for coordinating with these communities.\n\n<info added on 2025-05-02T01:12:18.130Z>\nThe documentation should include:\n\n1. A clear hierarchical structure with sections for:\n   - Overview of the namespace concept in BIDS\n   - Reserved namespaces explanation\n   - Namespace governance model\n   - Application process\n\n2. Specific technical details:\n   - Namespace format requirements (allowed characters, length limits)\n   - File naming conventions when using namespaces (e.g., `*_<namespace>-<suffix>.<extension>`)\n   - JSON schema validation considerations\n\n3. Practical examples showing:\n   - How to properly use namespaces in filenames\n   - How namespaces appear in directory structures\n   - Sample metadata that includes namespace-specific fields\n\n4. Cross-references to:\n   - The specification sections that define namespace behavior\n   - GitHub issue templates for namespace proposals\n   - Contact information for namespace maintainers\n\n5. A table listing current namespaces with columns for:\n   - Namespace identifier\n   - Maintaining organization/community\n   - Primary contact\n   - Brief description of purpose\n   - Link to namespace-specific documentation\n</info added on 2025-05-02T01:12:18.130Z>",
          "status": "done",
          "dependencies": [
            2,
            6
          ],
          "parentTaskId": 1
        },
        {
          "id": 8,
          "title": "Create CONTRIBUTING.md",
          "description": "Create a CONTRIBUTING.md file outlining how to contribute to the project.",
          "details": "Create CONTRIBUTING.md in the project root. Include general contribution guidelines (bug reports, feature requests, pull requests). Add a specific section detailing the process for proposing new namespaces, referencing the namespace documentation (from subtask 7) for detailed requirements and review criteria. Explain the governance model for namespace management and how to coordinate with existing namespace maintainers.\n\n<info added on 2025-05-02T01:12:53.279Z>\nI've reviewed the CONTRIBUTING.md file and it covers the essential contribution types and processes. Here are additional details to enhance it:\n\nFor the namespace proposal section, include a clear template format with required fields:\n- Namespace name\n- Purpose/problem it solves\n- Example use cases\n- Proposed API structure\n- Compatibility considerations with existing namespaces\n\nAdd a \"Development Environment Setup\" section with:\n- Required dependencies and versions\n- How to run tests locally\n- Linting and formatting requirements\n- Pre-commit hooks recommendation\n\nInclude a \"Code Review Process\" section explaining:\n- The review timeline expectations\n- Required approvals (minimum 2 maintainers)\n- Common review criteria (test coverage, documentation, API consistency)\n\nConsider adding a \"Community Conduct\" section referencing the Code of Conduct and explaining the project's communication channels and decision-making process.\n</info added on 2025-05-02T01:12:53.279Z>",
          "status": "done",
          "dependencies": [
            7
          ],
          "parentTaskId": 1
        }
      ]
    },
    {
      "id": 2,
      "title": "Develop Core Python Validation Library",
      "description": "Create a Python package that implements validation against the signalJourney JSON Schema with detailed error reporting.",
      "status": "done",
      "dependencies": [
        1
      ],
      "priority": "high",
      "details": "Implement a Python library that validates signalJourney JSON files against the schema defined in Task 1. Use jsonschema or a similar library for validation. Include functions to: 1) Validate a file against the schema, 2) Generate detailed error messages for invalid files, 3) Provide suggestions for fixing common errors, 4) Support different versions of the schema. Package the library for PyPI distribution with proper documentation. Include type hints and follow PEP 8 style guidelines. Consider BIDS context when validating, e.g., potentially checking for associated data files within a BIDS structure or handling root-level vs derivative-level journey files.",
      "testStrategy": "Create unit tests using pytest that cover validation of both valid and invalid files. Include edge cases such as missing required fields, incorrect data types, and invalid relationships between fields. Test version compatibility handling. Include tests for BIDS-specific validation scenarios.",
      "subtasks": [
        {
          "id": 1,
          "title": "Set up project structure and dependencies",
          "description": "Initialize the Python package structure with necessary files and dependencies for the validation library",
          "status": "done",
          "dependencies": [],
          "details": "Create a proper Python package structure including setup.py, README.md, and directory structure. Set up virtual environment. Add dependencies on jsonschema and other required libraries. Initialize git repository. Create package namespace and module structure. Set up testing framework (pytest). Configure type checking with mypy. Ensure PEP 8 compliance with tools like flake8 or black.\n\n<info added on 2025-05-02T01:29:14.940Z>\nFor the `signaljourney_validator` package structure:\n\n- Added `pyproject.toml` with Poetry configuration instead of setup.py for modern dependency management\n- Created core module files: `src/signaljourney_validator/validator.py`, `src/signaljourney_validator/exceptions.py`, `src/signaljourney_validator/schema_registry.py`\n- Set up test directory with structure: `tests/unit/`, `tests/integration/`, `tests/fixtures/`\n- Added CI configuration in `.github/workflows/python-tests.yml` for automated testing\n- Configured Ruff for linting and formatting (replacing flake8/black) with `.ruff.toml`\n- Created mypy configuration in `mypy.ini` with strict type checking enabled\n- Added `src/signaljourney_validator/py.typed` marker file for PEP 561 compliance\n- Included version management in `src/signaljourney_validator/__init__.py` with `__version__ = \"0.1.0\"`\n- Set up pre-commit hooks with `.pre-commit-config.yaml` for code quality checks\n</info added on 2025-05-02T01:29:14.940Z>"
        },
        {
          "id": 2,
          "title": "Implement core schema validation functionality",
          "description": "Create the primary validation module that validates signalJourney JSON files against the schema",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Implement a Validator class that loads and validates JSON files against the schema from Task 1. Create functions to load JSON schema files, validate documents, and return validation status. Handle different schema versions through a version parameter. Implement proper error handling for schema loading failures. Add type hints to all functions. Write unit tests for basic validation functionality. Ensure validation works for both file paths and JSON objects in memory.\n\n<info added on 2025-05-02T01:31:31.459Z>\nAdded implementation details:\n\n```python\nfrom pathlib import Path\nimport json\nfrom typing import Union, Dict, Any, Optional\nfrom jsonschema import validate, ValidationError\n\nclass SignalJourneyValidationError(Exception):\n    \"\"\"Custom exception for validation errors\"\"\"\n    pass\n\nclass Validator:\n    def __init__(self, schema_path: Optional[Union[str, Path, Dict[str, Any]]] = None):\n        \"\"\"\n        Initialize validator with schema\n        \n        Args:\n            schema_path: Path to schema file, dict containing schema, or None to use default\n        \"\"\"\n        self.schema = self._load_schema(schema_path)\n    \n    def _load_schema(self, schema_path: Optional[Union[str, Path, Dict[str, Any]]]) -> Dict[str, Any]:\n        if schema_path is None:\n            # Use default schema path relative to package\n            default_path = Path(__file__).parent / \"schemas\" / \"signaljourney-schema.json\"\n            return self._load_schema(default_path)\n        \n        if isinstance(schema_path, dict):\n            return schema_path\n            \n        try:\n            with open(schema_path, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            raise FileNotFoundError(f\"Schema file not found: {schema_path}\")\n        except json.JSONDecodeError:\n            raise ValueError(f\"Invalid JSON in schema file: {schema_path}\")\n    \n    def validate(self, document: Union[str, Path, Dict[str, Any]]) -> bool:\n        \"\"\"\n        Validate a document against the schema\n        \n        Args:\n            document: Path to JSON file, JSON string, or dict containing document\n            \n        Returns:\n            True if valid\n            \n        Raises:\n            SignalJourneyValidationError: If validation fails\n            FileNotFoundError: If document file not found\n            ValueError: If document contains invalid JSON\n        \"\"\"\n        # Load document if it's a path or string\n        if isinstance(document, (str, Path)) and not isinstance(document, dict):\n            try:\n                if Path(document).exists():\n                    with open(document, 'r') as f:\n                        document = json.load(f)\n                else:\n                    # Try parsing as JSON string\n                    document = json.loads(document)\n            except FileNotFoundError:\n                raise FileNotFoundError(f\"Document file not found: {document}\")\n            except json.JSONDecodeError:\n                raise ValueError(f\"Invalid JSON in document: {document}\")\n        \n        # Validate\n        try:\n            validate(instance=document, schema=self.schema)\n            return True\n        except ValidationError as e:\n            raise SignalJourneyValidationError(f\"Validation failed: {str(e)}\")\n```\n</info added on 2025-05-02T01:31:31.459Z>"
        },
        {
          "id": 3,
          "title": "Develop detailed error reporting system",
          "description": "Enhance the validator to provide detailed, user-friendly error messages for validation failures",
          "status": "done",
          "dependencies": [
            2
          ],
          "details": "Extend the Validator to capture and format jsonschema validation errors. Create a custom ErrorReport class to structure validation errors. Map cryptic jsonschema error paths to human-readable field names. Include context information such as the location of errors in the document. Add severity levels for different types of validation errors. Implement error aggregation to show multiple errors at once. Write unit tests with various invalid documents to verify error reporting.\n\n<info added on 2025-05-02T01:34:17.022Z>\nHere's the additional implementation information for the error reporting system:\n\n```python\n# Implementation details for ValidationErrorDetail dataclass\n@dataclass\nclass ValidationErrorDetail:\n    path: str  # JSON path to the error location\n    message: str  # Human-readable error message\n    schema_path: str  # Path in the schema that failed validation\n    severity: str = \"error\"  # Default severity level\n    context: Optional[Dict] = None  # Additional context about the error\n    \n    def human_readable_path(self) -> str:\n        \"\"\"Converts JSON path to human-readable format\"\"\"\n        return \".\".join(str(p) for p in self.path) if self.path else \"document root\"\n\n# Error handling in Validator.validate method\ndef validate(self, document: Dict, raise_exceptions: bool = True) -> Union[bool, List[ValidationErrorDetail]]:\n    validator = Draft7Validator(self.schema)\n    errors = []\n    \n    for error in validator.iter_errors(document):\n        detail = ValidationErrorDetail(\n            path=error.path,\n            message=error.message,\n            schema_path=error.schema_path,\n            context={\"value\": error.instance} if not isinstance(error.instance, dict) else None\n        )\n        \n        # Set severity based on error type\n        if \"required\" in error.schema_path:\n            detail.severity = \"critical\"\n        elif \"type\" in error.schema_path:\n            detail.severity = \"error\"\n        else:\n            detail.severity = \"warning\"\n            \n        errors.append(detail)\n    \n    if errors and raise_exceptions:\n        raise SignalJourneyValidationError(\"Document validation failed\", errors=errors)\n    \n    return [] if not errors else errors\n```\n\nAdded unit tests in `tests/test_error_reporting.py` to verify:\n- Error path translation to human-readable format\n- Proper severity assignment based on error type\n- Aggregation of multiple errors from different parts of the document\n- Context information for primitive values that failed validation\n</info added on 2025-05-02T01:34:17.022Z>"
        },
        {
          "id": 4,
          "title": "Implement error correction suggestions",
          "description": "Add functionality to provide suggestions for fixing common validation errors",
          "status": "done",
          "dependencies": [
            3
          ],
          "details": "Create a suggestion engine that analyzes validation errors and provides fixing hints. Implement pattern matching for common error types (e.g., type mismatches, missing required fields, format errors). Add domain-specific suggestions for signalJourney-specific fields. Implement fuzzy matching for enum values to suggest closest valid options. Create a suggestion formatter to present fixes in a user-friendly way. Write comprehensive tests for the suggestion system with various error scenarios.\n\n<info added on 2025-05-02T01:37:02.661Z>\nHere's additional implementation information for the error correction suggestions:\n\nThe `generate_suggestion` method uses a strategy pattern with specialized handlers for each validator type:\n\n- For `required` errors: Suggests adding the missing field with appropriate type placeholder\n- For `type` errors: Provides type conversion examples (e.g., \"Convert '123' to integer using int()\")\n- For `pattern` errors: Shows example values that match the required pattern\n- For `enum` errors: Uses Levenshtein distance to find closest matches (threshold configurable)\n\nFuzzy matching implementation details:\n- Set default similarity threshold to 75%\n- Added configuration option `FUZZY_MATCH_THRESHOLD` in settings\n- Implemented caching for fuzzy matches to improve performance\n\nAdded unit tests covering:\n- Suggestion generation for each error type\n- Edge cases (empty values, complex nested structures)\n- Performance tests for fuzzy matching with large enum sets\n\nThe suggestion formatter supports multiple output formats:\n- Plain text (default)\n- Markdown with code highlighting\n- JSON for programmatic consumption\n\nAdded documentation with examples of common error patterns and their suggested fixes.\n</info added on 2025-05-02T01:37:02.661Z>"
        },
        {
          "id": 5,
          "title": "Package library and create documentation",
          "description": "Finalize the package for distribution and create comprehensive documentation",
          "status": "done",
          "dependencies": [
            2,
            3,
            4
          ],
          "details": "Complete setup.py with all metadata for PyPI distribution. Generate API documentation using Sphinx or a similar tool. Write a comprehensive README with installation and usage examples. Create detailed API reference documentation with examples for each function. Add docstrings to all public functions and classes. Implement a command-line interface for validation. Create example scripts demonstrating library usage. Prepare the package for PyPI publication with proper versioning. Set up CI/CD for automated testing and deployment.\n\n<info added on 2025-05-02T01:37:42.895Z>\nGreat progress on the packaging setup. Here's additional information for the subtask:\n\nFor CI/CD setup:\n- Created `.github/workflows/python-package.yml` with jobs for:\n  - Testing across Python 3.8-3.11 on Ubuntu, macOS, and Windows\n  - Code quality checks using flake8, black, and isort\n  - Test coverage reporting with codecov integration\n  - Automated PyPI deployment on tagged releases\n\nDocumentation progress:\n- Initialized Sphinx documentation structure with `sphinx-quickstart`\n- Configured autodoc extension to generate API docs from docstrings\n- Added custom theme (Read the Docs) with responsive layout\n- Created initial documentation sections: Getting Started, API Reference, Examples, Contributing\n- Setup documentation hosting on Read the Docs with version control\n\nLicense implementation:\n- Added MIT License file with appropriate copyright notice\n- Updated all source files with license headers\n- Included license classifier in package metadata\n\nPyPI preparation:\n- Created PyPI API token for automated publishing\n- Added token to GitHub repository secrets\n- Verified package builds correctly with `python -m build`\n- Tested installation from local build with `pip install dist/*.whl`\n- Prepared release checklist for version management\n</info added on 2025-05-02T01:37:42.895Z>"
        },
        {
          "id": 6,
          "title": "Implement BIDS context validation",
          "description": "Add functionality to validate signalJourney files within a BIDS directory structure context",
          "status": "done",
          "dependencies": [
            2
          ],
          "details": "Develop functionality to detect and validate signalJourney files within a BIDS directory structure. Implement checks for associated data files referenced in the journey file. Create different validation rules for root-level vs derivative-level journey files. Add BIDS path validation to ensure journey files are properly located. Implement functions to traverse BIDS directory structures to find and validate all journey files. Add configuration options to enable/disable BIDS-specific validations. Write tests using sample BIDS datasets to verify BIDS context validation.\n\n<info added on 2025-05-02T01:38:40.335Z>\nHere's additional information for the BIDS context validation implementation:\n\n```python\ndef _validate_bids_context(self, journey_path: Path, bids_root: Path) -> List[ValidationError]:\n    \"\"\"\n    Validate a signalJourney file within a BIDS directory structure.\n    \n    Parameters:\n        journey_path: Path to the signalJourney file\n        bids_root: Path to the BIDS root directory\n    \n    Returns:\n        List of validation errors related to BIDS context\n    \"\"\"\n    errors = []\n    \n    # 1. Validate file placement\n    rel_path = journey_path.relative_to(bids_root)\n    parts = rel_path.parts\n    \n    # Check if in derivatives or root\n    is_derivative = 'derivatives' in parts\n    \n    if is_derivative:\n        # Derivatives validation rules\n        pipeline_index = parts.index('derivatives') + 1\n        if len(parts) <= pipeline_index:\n            errors.append(ValidationError(\n                \"signalJourney file in derivatives must be within a pipeline directory\",\n                path=str(journey_path)\n            ))\n    else:\n        # Root validation rules\n        if not (len(parts) >= 2 and parts[0] == 'sub-'):\n            errors.append(ValidationError(\n                \"Root-level signalJourney file must be within a subject directory\",\n                path=str(journey_path)\n            ))\n    \n    # 2. Validate referenced files exist\n    with open(journey_path, 'r') as f:\n        journey_data = json.load(f)\n    \n    for step in journey_data.get('steps', []):\n        input_files = step.get('inputs', {}).values()\n        for file_path in input_files:\n            if isinstance(file_path, str) and not file_path.startswith('http'):\n                full_path = bids_root / file_path\n                if not full_path.exists():\n                    errors.append(ValidationError(\n                        f\"Referenced file does not exist: {file_path}\",\n                        path=f\"$.steps[?].inputs.{file_path}\"\n                    ))\n    \n    # 3. Validate BIDS naming conventions\n    filename = journey_path.name\n    if not filename.endswith('_signalJourney.json'):\n        errors.append(ValidationError(\n            \"signalJourney filename must end with '_signalJourney.json'\",\n            path=str(journey_path)\n        ))\n    \n    return errors\n```\n\nImplementation notes:\n1. The BIDS validator should handle different validation rules for root vs. derivatives placement\n2. Add a utility function to recursively find all signalJourney files in a BIDS directory:\n\n```python\ndef find_journey_files(bids_root: Path) -> List[Path]:\n    \"\"\"Find all signalJourney files in a BIDS directory structure\"\"\"\n    return list(bids_root.glob('**/*_signalJourney.json'))\n```\n\n3. Consider adding a configuration class for BIDS validation settings:\n\n```python\n@dataclass\nclass BIDSValidationConfig:\n    validate_file_existence: bool = True\n    validate_placement: bool = True\n    validate_naming: bool = True\n    allow_external_references: bool = True\n```\n\n4. Add CLI support for BIDS validation with arguments like:\n   `--bids-root /path/to/bids --validate-all-journeys`\n</info added on 2025-05-02T01:38:40.335Z>"
        }
      ]
    },
    {
      "id": 3,
      "title": "Implement Command-Line Interface for Validation",
      "description": "Create a command-line tool that leverages the Python validation library to validate signalJourney files.",
      "status": "done",
      "dependencies": [
        2
      ],
      "priority": "medium",
      "details": "Build a command-line interface (CLI) using argparse or click that wraps the validation library from Task 2. The CLI should: 1) Accept file paths or directories as input, 2) Validate single files or recursively validate directories, 3) Output validation results in human-readable format, 4) Provide options for verbose output, JSON output, and exit codes for scripting, 5) Include help documentation and examples. Add installation instructions for pip installation. The CLI should ideally be BIDS-aware, potentially offering options to validate files within a BIDS dataset structure or handle root-level journey files correctly.",
      "testStrategy": "Create integration tests that verify the CLI correctly processes valid and invalid files. Test directory recursion, different output formats, and exit codes. Include tests for help documentation and argument parsing. Test BIDS-specific functionality with sample BIDS dataset structures.",
      "subtasks": [
        {
          "id": 1,
          "title": "Set up CLI framework and basic file validation",
          "description": "Create the basic command-line interface structure using argparse or click that can accept file paths and perform basic validation on individual files.",
          "status": "done",
          "dependencies": [],
          "details": "1) Choose between argparse or click (click is recommended for more complex CLIs). 2) Set up the basic CLI structure with a main entry point. 3) Implement argument parsing for file paths. 4) Connect to the validation library to validate individual files. 5) Implement basic output of validation results. 6) Add proper error handling for file not found or permission issues.\n\n<info added on 2025-05-02T01:44:07.832Z>\nHere's the additional information to add:\n\n```python\n# Example implementation for cli.py\nimport click\nimport sys\nfrom pathlib import Path\nfrom .validator import Validator\n\n@click.group()\ndef cli():\n    \"\"\"SignalJourney validation tools.\"\"\"\n    pass\n\n@cli.command()\n@click.argument('file_path', type=click.Path(exists=True, readable=True, path_type=Path))\n@click.option('--schema', '-s', help='Path to custom schema file', type=click.Path(exists=True, readable=True, path_type=Path))\ndef validate(file_path, schema=None):\n    \"\"\"Validate a SignalJourney file against the schema.\"\"\"\n    validator = Validator(schema_path=schema)\n    \n    try:\n        result = validator.validate_file(file_path)\n        if result.is_valid:\n            click.echo(click.style(f\"✓ {file_path} is valid\", fg=\"green\"))\n            return 0\n        else:\n            click.echo(click.style(f\"✗ {file_path} has validation errors:\", fg=\"red\"))\n            for error in result.errors:\n                click.echo(f\"  - {error}\")\n            return 1\n    except Exception as e:\n        click.echo(click.style(f\"Error: {str(e)}\", fg=\"red\"))\n        return 1\n\nif __name__ == '__main__':\n    sys.exit(cli())\n```\n\nFor pyproject.toml, add:\n```toml\n[project.scripts]\nsignaljourney-validate = \"signaljourney_validator.cli:cli\"\n\n[project.dependencies]\nclick = \"^8.1.3\"\n```\n\nConsider adding a progress bar for multiple file validation using `click.progressbar()` and implementing colorized output for better user experience.\n</info added on 2025-05-02T01:44:07.832Z>"
        },
        {
          "id": 2,
          "title": "Implement directory handling and recursive validation",
          "description": "Extend the CLI to handle directory inputs and recursively validate all signalJourney files within directories.",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "1) Add logic to detect if the input path is a file or directory. 2) Implement recursive directory traversal to find all relevant files (consider allowing file pattern matching). 3) Process each file through the validation function. 4) Handle errors gracefully when processing multiple files. 5) Implement progress indication for large directories. 6) Consider adding a flag to control recursion depth.\n\n<info added on 2025-05-02T01:44:43.944Z>\nFor the directory handling implementation:\n\n- Used `os.path.isdir()` and `os.path.isfile()` to differentiate between directory and file inputs\n- Added `--pattern` option (default: \"*_signalJourney.json\") to allow custom file pattern matching using glob syntax\n- Implemented `--max-depth` integer option to control recursion depth (default: unlimited when recursive flag is set)\n- Added colored output formatting to clearly distinguish between files during batch validation\n- Implemented parallel processing option (`--parallel / -p`) with configurable worker count for faster validation of large directories\n- Added summary statistics after batch validation showing total files processed, success count, and failure count\n- Implemented early termination option (`--fail-fast / -f`) to stop processing on first validation error\n- Added verbose logging of directory traversal with `--verbose` flag to help debug complex directory structures\n- Created helper function `find_signal_journey_files()` that handles all path resolution logic separately from validation logic\n</info added on 2025-05-02T01:44:43.944Z>"
        },
        {
          "id": 3,
          "title": "Implement output formatting options and exit codes",
          "description": "Add various output format options including verbose mode, JSON output, and appropriate exit codes for scripting integration.",
          "status": "done",
          "dependencies": [
            1,
            2
          ],
          "details": "1) Implement a verbose flag that shows detailed validation information. 2) Create a JSON output option that formats results in machine-readable JSON. 3) Design a consistent output structure for both human-readable and JSON formats. 4) Implement appropriate exit codes (0 for success, non-zero for validation failures or errors). 5) Add color coding for terminal output (using a library like colorama) to highlight errors/warnings. 6) Ensure all output modes handle both single file and directory validation results appropriately.\n\n<info added on 2025-05-02T01:45:30.135Z>\nFor the \"details\" section, I'll add:\n\n7) Implement the `--output-format` (`-o`) option with 'text' and 'json' choices, defaulting to 'text'. 8) Structure JSON output as a single object with 'status' field (overall pass/fail) and 'results' array containing per-file validation details. 9) Include detailed error information in JSON output with fields matching ValidationErrorDetail structure (line_number, error_type, message, suggestion). 10) Ensure color coding is only applied for terminal output and disabled for redirected output or when specified by --no-color flag. 11) For verbose text output, include validator name/version information and final summary statistics (files checked, passed, failed). 12) Suppress progress messages (directory scanning, skipped files) when using JSON output to ensure clean machine-readable output. 13) Return exit code 0 for successful validation, 1 for validation failures, and 2 for program errors (invalid arguments, file access issues).\n</info added on 2025-05-02T01:45:30.135Z>"
        },
        {
          "id": 4,
          "title": "Add help documentation and package for distribution",
          "description": "Complete the CLI with comprehensive help documentation, usage examples, and package it for pip installation.",
          "status": "done",
          "dependencies": [
            1,
            2,
            3
          ],
          "details": "1) Write detailed help text for all commands and options. 2) Add usage examples for common scenarios. 3) Create a proper Python package structure with setup.py. 4) Configure entry points for the CLI tool. 5) Write installation and usage instructions in README.md. 6) Test the pip installation process. 7) Consider adding shell completion support. 8) Ensure the package has appropriate metadata (author, version, description, etc.).\n\n<info added on 2025-05-02T01:46:22.046Z>\nFor the CLI help documentation improvements in `cli.py`, I recommend adding these specific implementation details:\n\n```python\n# Example implementation for enhanced help documentation\n\n# Main CLI group with improved help\n@click.group(context_settings={\"help_option_names\": [\"-h\", \"--help\"]})\n@click.version_option(version=__version__, prog_name=\"json-validator\")\ndef cli():\n    \"\"\"JSON Schema validation tool for validating JSON documents.\n    \n    This tool allows you to validate JSON files against JSON Schema definitions,\n    supporting both single file validation and recursive directory processing.\n    \"\"\"\n    pass\n\n# Enhanced validate command with detailed help\n@cli.command()\n@click.argument('path', \n                type=click.Path(exists=True),\n                help=\"Path to JSON file or directory to validate. For directories, all .json files will be processed.\")\n@click.option('--schema', '-s', \n              type=click.Path(exists=True, file_okay=True, dir_okay=False),\n              help=\"Path to JSON Schema file. Required unless schema is referenced in the JSON documents.\")\n@click.option('--recursive', '-r', \n              is_flag=True, \n              help=\"Process directories recursively, including all subdirectories.\")\n@click.option('--output-format', '-o',\n              type=click.Choice(['text', 'json', 'yaml']),\n              default='text',\n              help=\"Format for validation results output. Default: text\")\n@click.option('--verbose', '-v', \n              is_flag=True,\n              help=\"Enable verbose output with detailed validation information.\")\ndef validate(path, schema, recursive, output_format, verbose):\n    \"\"\"Validate JSON documents against a JSON Schema.\n    \n    Examples:\n        # Validate a single file against a schema\n        json-validator validate data.json --schema schema.json\n        \n        # Validate all JSON files in a directory\n        json-validator validate ./data_dir --schema schema.json\n        \n        # Recursive validation with JSON output\n        json-validator validate ./data_dir --schema schema.json --recursive --output-format json\n        \n        # Verbose validation with detailed error information\n        json-validator validate data.json --schema schema.json --verbose\n    \"\"\"\n    # Command implementation\n```\n\nInclude help text formatting best practices:\n- Use consistent sentence structure and punctuation\n- Start with action verbs for option descriptions\n- Include default values where applicable\n- Group related examples together with clear comments\n</info added on 2025-05-02T01:46:22.046Z>"
        },
        {
          "id": 5,
          "title": "Implement BIDS-aware functionality",
          "description": "Add BIDS dataset awareness to the CLI to properly handle validation within BIDS directory structures.",
          "status": "done",
          "dependencies": [
            1,
            2
          ],
          "details": "1) Add detection for BIDS dataset structures when scanning directories. 2) Implement special handling for root-level journey files in BIDS datasets. 3) Add command-line options to specify BIDS-specific validation rules or behaviors. 4) Ensure validation respects BIDS directory hierarchy and naming conventions. 5) Consider adding a dedicated BIDS validation mode that understands the relationship between journey files and other BIDS components. 6) Update help documentation to include BIDS-specific usage examples.\n\n<info added on 2025-05-02T01:47:21.527Z>\nHere's additional implementation information for the BIDS-aware functionality:\n\n```python\n# Implementation details for BIDS detection and validation\n\n# 1. BIDS dataset detection function\ndef is_bids_dataset(directory_path):\n    \"\"\"\n    Detect if a directory is a BIDS dataset by checking for:\n    - dataset_description.json file at the root\n    - Expected folder structure (sub-* directories)\n    \"\"\"\n    desc_file = os.path.join(directory_path, \"dataset_description.json\")\n    if not os.path.exists(desc_file):\n        return False\n    \n    # Check for at least one subject directory\n    subject_dirs = glob.glob(os.path.join(directory_path, \"sub-*\"))\n    return len([d for d in subject_dirs if os.path.isdir(d)]) > 0\n\n# 2. BIDS-specific validation rules\nclass BIDSValidator(Validator):\n    def __init__(self, bids_root, **kwargs):\n        super().__init__(**kwargs)\n        self.bids_root = bids_root\n        \n    def validate(self, journey_file):\n        # Get relative path from BIDS root\n        rel_path = os.path.relpath(journey_file, self.bids_root)\n        \n        # Special handling for root-level journey files\n        if '/' not in rel_path:\n            return self._validate_root_level_journey(journey_file)\n        \n        # Handle subject/session level journey files\n        if rel_path.startswith('sub-'):\n            return self._validate_subject_level_journey(journey_file)\n            \n        return super().validate(journey_file)\n```\n\nWhen implementing the CLI integration:\n- Store BIDS context in the validation process to track relationships between journey files\n- Implement special handling for derivatives/ directory which may contain journey files\n- Add BIDS-specific error messages that reference the BIDS specification\n- Consider implementing a BIDS summary report showing all journey files organized by subject/session\n</info added on 2025-05-02T01:47:21.527Z>"
        }
      ]
    },
    {
      "id": 4,
      "title": "Create Sample signalJourney Files for Common Processing Pipelines",
      "description": "Develop a set of example signalJourney JSON files that represent common biosignal processing workflows.",
      "status": "done",
      "dependencies": [
        1
      ],
      "priority": "medium",
      "details": "Create at least 5 example signalJourney files that document common processing pipelines for EEG/MEG data. Include examples for: 1) Basic preprocessing (filtering, referencing, artifact rejection), 2) ICA decomposition and cleaning, 3) Time-frequency analysis, 4) Source localization, 5) Connectivity analysis. Each example should include realistic parameters, quality metrics, and function references to common tools (EEGLAB, MNE-Python, Fieldtrip). Ensure all examples validate against the schema from Task 1.",
      "testStrategy": "Validate all examples against the schema using the validation library from Task 2. Have domain experts review the examples for accuracy and completeness. Test that the examples cover the range of common processing approaches in the field.",
      "subtasks": [
        {
          "id": 1,
          "title": "Research and document common parameters for biosignal processing pipelines",
          "description": "Research and document typical parameters, function calls, and quality metrics used in the five required processing pipelines across EEGLAB, MNE-Python, and Fieldtrip.",
          "status": "done",
          "dependencies": [],
          "details": "For each of the five required pipelines (basic preprocessing, ICA decomposition, time-frequency analysis, source localization, and connectivity analysis), document: 1) Common function names in each toolbox, 2) Typical parameter ranges and default values, 3) Standard quality metrics used to evaluate results, 4) Typical processing sequence. Create a structured document organizing this information by pipeline type and toolbox for reference when creating the actual JSON files."
        },
        {
          "id": 2,
          "title": "Create basic preprocessing and ICA decomposition example files",
          "description": "Develop two signalJourney JSON files for basic preprocessing and ICA decomposition workflows.",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Using the research from subtask 1, create two complete signalJourney JSON files: 1) Basic preprocessing pipeline including filtering (high-pass, low-pass), referencing, and artifact rejection steps with realistic parameters. 2) ICA decomposition and cleaning workflow including preprocessing steps, ICA computation, component selection criteria, and artifact removal. Include appropriate metadata, quality metrics (like variance explained, residual noise), and references to specific functions in common toolboxes. Ensure both examples follow the schema structure from Task 1."
        },
        {
          "id": 3,
          "title": "Create time-frequency analysis example file",
          "description": "Develop a signalJourney JSON file for time-frequency analysis workflow.",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Create a comprehensive signalJourney JSON file for time-frequency analysis that includes: 1) Necessary preprocessing steps, 2) Time-frequency decomposition methods (e.g., wavelet transform, short-time Fourier transform), 3) Parameters for frequency bands, time windows, and baseline correction, 4) Visualization settings, 5) Statistical analysis steps. Include quality metrics such as signal-to-noise ratio and references to specific functions in EEGLAB, MNE-Python, and Fieldtrip. Ensure the example validates against the schema from Task 1."
        },
        {
          "id": 4,
          "title": "Create source localization example file",
          "description": "Develop a signalJourney JSON file for source localization workflow.",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Create a detailed signalJourney JSON file for source localization that includes: 1) Preprocessing requirements, 2) Head model creation steps, 3) Forward modeling parameters, 4) Inverse solution methods (e.g., MNE, LORETA, beamforming), 5) Source space definition, 6) Visualization settings. Include appropriate quality metrics like explained variance, cross-validation metrics, and references to specific functions in common toolboxes. Ensure the example includes realistic parameters for different head models and inverse methods, and validates against the schema from Task 1."
        },
        {
          "id": 5,
          "title": "Create connectivity analysis example file and validate all examples",
          "description": "Develop a signalJourney JSON file for connectivity analysis workflow and validate all five examples against the schema.",
          "status": "done",
          "dependencies": [
            1,
            2,
            3,
            4
          ],
          "details": "Create a comprehensive signalJourney JSON file for connectivity analysis that includes: 1) Preprocessing requirements, 2) Connectivity measure calculations (e.g., coherence, phase locking value, Granger causality), 3) Parameters for frequency bands and time windows, 4) Network analysis steps, 5) Visualization settings. Include quality metrics like statistical significance thresholds and surrogate data testing. Then, validate all five created examples against the schema from Task 1, ensuring they are properly formatted, contain all required fields, and represent realistic workflows. Make any necessary adjustments to ensure all examples are consistent in structure while accurately representing their specific pipeline types."
        }
      ]
    },
    {
      "id": 5,
      "title": "Develop MATLAB Tools for Reading/Writing signalJourney Files",
      "description": "Create a MATLAB library for working with signalJourney files, including reading, writing, and basic validation.",
      "status": "done",
      "dependencies": [
        1
      ],
      "priority": "high",
      "details": "Implement a MATLAB toolbox that provides functions to: 1) Read signalJourney JSON files into MATLAB structures, 2) Write MATLAB structures to signalJourney JSON files, 3) Perform basic validation of structures against the specification, 4) Convert between different versions of the specification if needed. Include documentation, examples, and a test suite. Package the toolbox for distribution via MATLAB File Exchange. Ensure compatibility with MATLAB R2019b and newer.",
      "testStrategy": "Create a comprehensive test suite using MATLAB's testing framework. Test reading and writing of all example files from Task 4. Verify round-trip conversion (read-write-read) preserves all information. Test validation functionality against valid and invalid structures.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement JSON parsing functions for signalJourney files",
          "description": "Create core functions to read signalJourney JSON files into MATLAB structures with proper data type handling",
          "status": "done",
          "dependencies": [],
          "details": "Develop a function `readSignalJourney(filename)` that uses MATLAB's built-in `jsondecode` function to parse signalJourney files. Implement proper handling for all data types in the specification, including arrays, nested objects, and special values. Include error handling for file access issues and malformed JSON. Create helper functions to process specific sections of the signalJourney format (metadata, signals, events, etc.). Return a well-structured MATLAB object that preserves the hierarchical nature of the signalJourney format.\n\n<info added on 2025-05-02T01:40:06.870Z>\nHere's the additional information to add:\n\n```matlab\nfunction journeyData = readSignalJourney(filename)\n    % READSIGNALJOURNEY Reads and parses a signalJourney JSON file\n    %   journeyData = READSIGNALJOURNEY(filename) reads the specified JSON file\n    %   and returns a structured MATLAB object containing the parsed data\n    \n    arguments\n        filename (1,:) char {mustBeFile}\n    end\n    \n    try\n        % Read the file content\n        fileContent = fileread(filename);\n    catch ME\n        error('readSignalJourney:fileReadError', ...\n              'Failed to read file \"%s\": %s', filename, ME.message);\n    end\n    \n    try\n        % Parse JSON content\n        journeyData = jsondecode(fileContent);\n    catch ME\n        error('readSignalJourney:jsonDecodeError', ...\n              'Failed to parse JSON in file \"%s\": %s', filename, ME.message);\n    end\n    \n    % Validate required top-level fields\n    requiredFields = {'metadata', 'signals', 'events'};\n    missingFields = setdiff(requiredFields, fieldnames(journeyData));\n    \n    if ~isempty(missingFields)\n        warning('readSignalJourney:missingFields', ...\n                'The following required fields are missing: %s', ...\n                strjoin(missingFields, ', '));\n    end\n    \n    % Process specific sections with helper functions\n    if isfield(journeyData, 'metadata')\n        journeyData.metadata = processMetadata(journeyData.metadata);\n    end\n    \n    if isfield(journeyData, 'signals')\n        journeyData.signals = processSignals(journeyData.signals);\n    end\n    \n    if isfield(journeyData, 'events')\n        journeyData.events = processEvents(journeyData.events);\n    end\nend\n\nfunction metadata = processMetadata(metadata)\n    % Convert timestamp strings to datetime objects\n    if isfield(metadata, 'timestamp')\n        metadata.timestamp = datetime(metadata.timestamp, ...\n                                     'InputFormat', 'yyyy-MM-dd''T''HH:mm:ss.SSS''Z''', ...\n                                     'TimeZone', 'UTC');\n    end\n    \n    % Additional metadata processing as needed\nend\n\nfunction signals = processSignals(signals)\n    % Process each signal\n    for i = 1:length(signals)\n        % Convert data types if needed\n        if isfield(signals(i), 'samplingRate')\n            signals(i).samplingRate = double(signals(i).samplingRate);\n        end\n        \n        % Process signal data arrays for efficient MATLAB operations\n        if isfield(signals(i), 'data')\n            signals(i).data = double(signals(i).data);\n        end\n    end\nend\n\nfunction events = processEvents(events)\n    % Process each event\n    for i = 1:length(events)\n        % Convert timestamp strings to datetime objects\n        if isfield(events(i), 'timestamp')\n            events(i).timestamp = datetime(events(i).timestamp, ...\n                                         'InputFormat', 'yyyy-MM-dd''T''HH:mm:ss.SSS''Z''', ...\n                                         'TimeZone', 'UTC');\n        end\n    end\nend\n```\n\nThis implementation includes helper functions for processing specific sections of the signalJourney format, converts timestamps to MATLAB datetime objects, ensures numeric data is properly typed as double for MATLAB compatibility, and provides detailed error messages for troubleshooting.\n</info added on 2025-05-02T01:40:06.870Z>"
        },
        {
          "id": 2,
          "title": "Implement JSON writing functions for signalJourney files",
          "description": "Create functions to write MATLAB structures to signalJourney JSON files with proper formatting",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Develop a function `writeSignalJourney(data, filename)` that converts MATLAB structures to JSON using `jsonencode`. Ensure proper handling of all MATLAB data types, including numeric arrays, cell arrays, and structs. Implement pretty-printing for the output JSON to ensure human readability. Add validation to ensure the MATLAB structure contains all required fields before writing. Include error handling for file access issues and invalid MATLAB structures. Create helper functions to properly format specific sections of the signalJourney format.\n\n<info added on 2025-05-02T01:40:50.065Z>\n```matlab\nfunction success = writeSignalJourney(data, filename)\n    % WRITESIGNALJOURNEY Writes a MATLAB structure to a signalJourney JSON file\n    %\n    % Syntax:\n    %   success = writeSignalJourney(data, filename)\n    %\n    % Inputs:\n    %   data - MATLAB structure containing signalJourney data\n    %   filename - String specifying the output file path\n    %\n    % Outputs:\n    %   success - Boolean indicating whether the write operation succeeded\n    \n    arguments\n        data struct\n        filename (1,:) char\n    end\n    \n    % Define required top-level fields for signalJourney format\n    requiredFields = {'metadata', 'signals', 'events'};\n    \n    % Check for required fields\n    missingFields = setdiff(requiredFields, fieldnames(data));\n    if ~isempty(missingFields)\n        warning('writeSignalJourney:missingFields', ...\n                'The following required fields are missing: %s', ...\n                strjoin(missingFields, ', '));\n    end\n    \n    % Set JSON encoding options for pretty printing\n    options = struct('Indent', '  ', 'ConvertInfAndNaN', true);\n    \n    try\n        % Convert MATLAB structure to JSON string\n        jsonStr = jsonencode(data, options);\n        \n        % Ensure the JSON string ends with a newline\n        if jsonStr(end) ~= newline\n            jsonStr = [jsonStr newline];\n        end\n        \n        % Write JSON string to file\n        try\n            fileID = fopen(filename, 'w', 'n', 'UTF-8');\n            if fileID == -1\n                error('Failed to open file for writing: %s', filename);\n            end\n            fprintf(fileID, '%s', jsonStr);\n            fclose(fileID);\n            success = true;\n        catch fileErr\n            error('writeSignalJourney:fileWriteError', ...\n                  'Error writing to file: %s', fileErr.message);\n        end\n    catch jsonErr\n        error('writeSignalJourney:jsonEncodeError', ...\n              'Error encoding JSON: %s', jsonErr.message);\n    end\nend\n```\n\nAlso added a helper function `formatSignalJourneyStruct.m` to prepare MATLAB structures for JSON conversion:\n\n```matlab\nfunction formattedData = formatSignalJourneyStruct(data)\n    % FORMATSIGNALJOURNEYDATA Prepares a MATLAB structure for signalJourney JSON conversion\n    %\n    % Handles special cases like:\n    % - Converting datetime objects to ISO 8601 strings\n    % - Ensuring numeric arrays use consistent precision\n    % - Formatting signal data according to signalJourney specifications\n    \n    formattedData = data;\n    \n    % Format metadata timestamps\n    if isfield(formattedData, 'metadata') && isfield(formattedData.metadata, 'timestamp')\n        if isdatetime(formattedData.metadata.timestamp)\n            formattedData.metadata.timestamp = datestr(formattedData.metadata.timestamp, 'yyyy-mm-ddTHH:MM:SS.FFFZ');\n        end\n    end\n    \n    % Format signal data\n    if isfield(formattedData, 'signals')\n        for i = 1:length(formattedData.signals)\n            % Ensure consistent numeric precision\n            if isfield(formattedData.signals{i}, 'data') && isnumeric(formattedData.signals{i}.data)\n                % Convert to double precision if not already\n                formattedData.signals{i}.data = double(formattedData.signals{i}.data);\n            end\n        end\n    end\nend\n```\n</info added on 2025-05-02T01:40:50.065Z>"
        },
        {
          "id": 3,
          "title": "Implement validation functions for signalJourney structures",
          "description": "Create functions to validate MATLAB structures against the signalJourney specification",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Develop a function `validateSignalJourney(data)` that checks if a MATLAB structure conforms to the signalJourney specification. Implement validation for required fields, data types, and value ranges. Create separate validation functions for each major section of the specification (metadata, signals, events, etc.). Return detailed error messages for validation failures, including the path to the problematic field. Implement warning generation for non-critical issues. Add support for validating against different versions of the specification if needed.\n\n<info added on 2025-05-02T01:41:50.489Z>\n```matlab\nfunction [isValid, messages] = validateSignalJourney(data)\n    isValid = true;\n    messages = {};\n    \n    % Check if input is a struct\n    if ~isstruct(data)\n        isValid = false;\n        messages{end+1} = 'Error: Input must be a MATLAB structure';\n        return;\n    end\n    \n    % Required top-level fields\n    requiredFields = {'metadata', 'signals'};\n    for i = 1:length(requiredFields)\n        if ~isfield(data, requiredFields{i})\n            isValid = false;\n            messages{end+1} = ['Error: Missing required field \"', requiredFields{i}, '\"'];\n        end\n    end\n    \n    % Validate metadata if present\n    if isfield(data, 'metadata')\n        [metaValid, metaMessages] = validateMetadata(data.metadata);\n        if ~metaValid\n            isValid = false;\n            messages = [messages, metaMessages];\n        end\n    end\n    \n    % Validate signals if present\n    if isfield(data, 'signals')\n        [sigValid, sigMessages] = validateSignals(data.signals);\n        if ~sigValid\n            isValid = false;\n            messages = [messages, sigMessages];\n        end\n    end\n    \n    % Validate events if present (optional field)\n    if isfield(data, 'events')\n        [evtValid, evtMessages] = validateEvents(data.events);\n        if ~evtValid\n            isValid = false;\n            messages = [messages, evtMessages];\n        end\n    end\n    \n    % Validate processingSteps if present (optional field)\n    if isfield(data, 'processingSteps')\n        [procValid, procMessages] = validateProcessingSteps(data.processingSteps);\n        if ~procValid\n            isValid = false;\n            messages = [messages, procMessages];\n        end\n    end\nend\n\n% Helper validation functions for each section\nfunction [isValid, messages] = validateMetadata(metadata)\n    isValid = true;\n    messages = {};\n    \n    % Check required metadata fields\n    requiredFields = {'title', 'dateCreated', 'version'};\n    for i = 1:length(requiredFields)\n        if ~isfield(metadata, requiredFields{i})\n            isValid = false;\n            messages{end+1} = ['Error: Missing required metadata field \"', requiredFields{i}, '\"'];\n        end\n    end\n    \n    % Type checking for common fields\n    if isfield(metadata, 'title') && ~ischar(metadata.title)\n        isValid = false;\n        messages{end+1} = 'Error: metadata.title must be a string';\n    end\n    \n    if isfield(metadata, 'version') && ~ischar(metadata.version)\n        isValid = false;\n        messages{end+1} = 'Error: metadata.version must be a string';\n    end\nend\n\nfunction [isValid, messages] = validateSignals(signals)\n    isValid = true;\n    messages = {};\n    \n    % Signals must be a cell array or struct array\n    if ~iscell(signals) && ~isstruct(signals)\n        isValid = false;\n        messages{end+1} = 'Error: signals must be a cell array or struct array';\n        return;\n    end\n    \n    % If it's a cell array, each element must be a struct\n    if iscell(signals)\n        for i = 1:length(signals)\n            if ~isstruct(signals{i})\n                isValid = false;\n                messages{end+1} = ['Error: signals{', num2str(i), '} must be a struct'];\n                continue;\n            end\n            \n            % Validate individual signal\n            [sigValid, sigMessages] = validateSignal(signals{i}, i);\n            if ~sigValid\n                isValid = false;\n                messages = [messages, sigMessages];\n            end\n        end\n    else\n        % It's a struct array, validate each element\n        for i = 1:length(signals)\n            [sigValid, sigMessages] = validateSignal(signals(i), i);\n            if ~sigValid\n                isValid = false;\n                messages = [messages, sigMessages];\n            end\n        end\n    end\nend\n\nfunction [isValid, messages] = validateSignal(signal, idx)\n    isValid = true;\n    messages = {};\n    \n    % Required fields for each signal\n    requiredFields = {'name', 'data'};\n    for i = 1:length(requiredFields)\n        if ~isfield(signal, requiredFields{i})\n            isValid = false;\n            messages{end+1} = ['Error: Missing required field \"', requiredFields{i}, '\" in signal ', num2str(idx)];\n        end\n    end\n    \n    % Check that data is numeric\n    if isfield(signal, 'data') && ~isnumeric(signal.data)\n        isValid = false;\n        messages{end+1} = ['Error: signal(', num2str(idx), ').data must be numeric'];\n    end\nend\n\n% Additional validation functions for events and processingSteps would follow similar patterns\n```\n\nThis implementation provides concrete validation logic for the signalJourney structure, with separate validation functions for each major section. The code includes proper error handling with specific messages that identify the exact location of validation failures.\n</info added on 2025-05-02T01:41:50.489Z>"
        },
        {
          "id": 4,
          "title": "Implement version conversion functions for signalJourney files",
          "description": "Create functions to convert between different versions of the signalJourney specification",
          "status": "done",
          "dependencies": [
            1,
            3
          ],
          "details": "Develop functions to convert signalJourney structures between different specification versions. Create a function `convertSignalJourneyVersion(data, targetVersion)` that transforms a structure to comply with the target version. Implement specific conversion logic for each version pair (e.g., v1 to v2, v2 to v3). Include validation before and after conversion to ensure data integrity. Document all changes made during conversion, including any potential data loss. Handle backward and forward compatibility issues appropriately.\n\n<info added on 2025-05-02T01:42:31.518Z>\nAdd the following implementation details:\n\nThe function should follow this implementation pattern:\n\n```matlab\nfunction data = convertSignalJourneyVersion(data, targetVersion)\n    % Get current version\n    currentVersion = data.sj_version;\n    \n    % Define version conversion path\n    conversionPath = determineConversionPath(currentVersion, targetVersion);\n    \n    % Apply conversions sequentially\n    for i = 1:length(conversionPath)-1\n        fromVer = conversionPath(i);\n        toVer = conversionPath(i+1);\n        data = applyVersionConversion(data, fromVer, toVer);\n    end\nend\n```\n\nImplement specific conversion functions for each version pair:\n- `v1_to_v2.m`: Handles renaming of fields, restructuring of signal metadata\n- `v2_to_v3.m`: Adds support for new signal types, updates timestamp format\n- `v3_to_v2.m`: Backward compatibility, with graceful degradation for features not in v2\n\nInclude a version compatibility matrix as a global constant to track which conversions are supported and their potential data loss implications.\n\nFor validation, implement `validateSignalJourneyVersion.m` that checks schema compliance before and after conversion, with detailed error reporting.\n\nLog all transformations applied during conversion in a `conversionLog` field that can be optionally returned to the caller.\n</info added on 2025-05-02T01:42:31.518Z>"
        },
        {
          "id": 5,
          "title": "Create documentation, examples, and package the toolbox",
          "description": "Prepare comprehensive documentation, usage examples, and package the toolbox for distribution",
          "status": "done",
          "dependencies": [
            1,
            2,
            3,
            4
          ],
          "details": "Create comprehensive documentation for all functions using MATLAB's documentation format. Include function signatures, parameter descriptions, return values, and examples. Develop a suite of example scripts demonstrating common use cases (reading files, modifying data, writing files, validation). Create a test suite using MATLAB's testing framework to verify all functionality. Package the toolbox according to MATLAB File Exchange requirements, including proper folder structure and metadata. Create a README file with installation instructions and quick-start guide. Verify compatibility with MATLAB R2019b and newer versions. Generate HTML documentation using MATLAB's publishing feature.\n\n<info added on 2025-05-02T01:43:03.709Z>\nFor the README.md:\n- Add a \"Getting Started\" section with step-by-step installation instructions\n- Include a troubleshooting section addressing common issues\n- Add badges for MATLAB version compatibility\n\nFor documentation:\n- Use MATLAB's `publish` function to generate HTML documentation with syntax highlighting\n- Implement function headers following MATLAB's documentation standard with sections:\n  - Syntax\n  - Description\n  - Input Arguments\n  - Output Arguments\n  - Examples\n  - See Also\n  - References\n\nFor testing:\n- Create unit tests using `matlab.unittest` framework\n- Implement test fixtures with sample TDMS files of varying complexity\n- Add integration tests that verify end-to-end workflows\n- Include performance benchmarks for large files\n\nFor examples:\n- Create categorized examples:\n  - Basic file operations\n  - Working with complex data types\n  - Batch processing multiple files\n  - Converting to/from other formats\n  - Custom validation workflows\n\nFor packaging:\n- Use MATLAB's Project tools to manage dependencies\n- Create a proper toolbox installation file (.mltbx)\n- Include version information in all files for traceability\n- Add continuous integration using MATLAB's GitHub Actions\n</info added on 2025-05-02T01:43:03.709Z>"
        }
      ]
    },
    {
      "id": 6,
      "title": "Implement EEGLAB Plugin for signalJourney Integration",
      "description": "Develop an EEGLAB plugin that allows users to export and import processing steps as signalJourney files.",
      "status": "deferred",
      "dependencies": [
        5
      ],
      "priority": "medium",
      "details": "Create an EEGLAB plugin that: 1) Tracks processing steps applied to EEG datasets, 2) Exports processing history as signalJourney JSON files, 3) Imports signalJourney files to recreate processing pipelines, 4) Provides a GUI for viewing and editing signalJourney metadata. The plugin should leverage the MATLAB tools from Task 5 and follow EEGLAB plugin development guidelines. Include documentation on installation and usage. Ensure compatibility with recent EEGLAB versions (2019 onwards).",
      "testStrategy": "Test the plugin with standard EEGLAB processing workflows. Verify that exported signalJourney files accurately capture all processing steps and parameters. Test importing signalJourney files and verify that processing is correctly reproduced. Test the GUI functionality for usability.",
      "subtasks": [
        {
          "id": 1,
          "title": "Set up EEGLAB plugin structure and configuration",
          "description": "Create the basic plugin structure following EEGLAB guidelines, including folder organization, plugin_init function, and configuration files.",
          "status": "pending",
          "dependencies": [],
          "details": "Create a plugin folder named 'signalJourney' with required EEGLAB plugin structure. Implement eegplugin_signalJourney.m as the entry point that adds menu items to EEGLAB. Create plugin_init.m to handle initialization and version checking. Set up configuration files to store plugin settings. Ensure the plugin registers properly with EEGLAB's plugin manager. Include version compatibility checks for EEGLAB 2019 onwards."
        },
        {
          "id": 2,
          "title": "Implement processing step tracking mechanism",
          "description": "Develop functions to track and store EEGLAB processing steps applied to datasets in a format compatible with signalJourney.",
          "status": "pending",
          "dependencies": [
            1
          ],
          "details": "Create a tracking system that hooks into EEGLAB's command history and EEG.history. Implement functions to capture processing parameters for each operation (filtering, ICA, epoch extraction, etc.). Store processing steps in a structured format compatible with signalJourney JSON specification. Include metadata like timestamps, parameter values, and processing order. Create a data structure that maintains the full processing pipeline state. Implement this as a background process that doesn't interfere with normal EEGLAB operations."
        },
        {
          "id": 3,
          "title": "Develop signalJourney export functionality",
          "description": "Create functions to export the tracked processing steps as signalJourney JSON files, including all required metadata.",
          "status": "pending",
          "dependencies": [
            2
          ],
          "details": "Implement export_signaljourney.m function that converts the tracked processing steps into signalJourney JSON format. Integrate with the MATLAB tools from Task 5 for JSON conversion. Include proper error handling and validation to ensure exported files meet the signalJourney specification. Add functionality to export dataset-specific metadata (subject info, recording parameters, etc.). Create a user dialog for specifying export options and file location. Ensure the export function handles all EEGLAB processing step types correctly."
        },
        {
          "id": 4,
          "title": "Implement signalJourney import functionality",
          "description": "Develop functions to import signalJourney files and recreate processing pipelines in EEGLAB.",
          "status": "pending",
          "dependencies": [
            3
          ],
          "details": "Create import_signaljourney.m function that parses signalJourney JSON files. Implement a system to translate signalJourney operations into equivalent EEGLAB commands. Build a pipeline execution engine that can apply the imported processing steps to a dataset in the correct order. Include validation to check if operations are supported in the current EEGLAB version. Implement error handling for cases where operations cannot be recreated. Add functionality to handle parameter mapping between signalJourney and EEGLAB formats."
        },
        {
          "id": 5,
          "title": "Create GUI for viewing and editing signalJourney metadata",
          "description": "Develop a graphical interface for users to view, edit, and manage signalJourney processing pipelines within EEGLAB.",
          "status": "pending",
          "dependencies": [
            3,
            4
          ],
          "details": "Create a MATLAB figure-based GUI that displays the processing pipeline in a readable format. Implement functionality to view detailed parameters for each processing step. Add controls to enable/disable specific processing steps. Include editing capabilities for modifying parameters of existing steps. Create visualization of the processing flow (e.g., flowchart or list view). Ensure the GUI follows EEGLAB's design patterns and integrates well with the existing interface. Add buttons for importing, exporting, and applying signalJourney pipelines."
        },
        {
          "id": 6,
          "title": "Write documentation and finalize plugin",
          "description": "Create comprehensive documentation, perform testing across EEGLAB versions, and prepare the plugin for distribution.",
          "status": "pending",
          "dependencies": [
            1,
            2,
            3,
            4,
            5
          ],
          "details": "Write detailed documentation including installation instructions, usage examples, and function references. Create a user manual with screenshots and step-by-step guides. Implement help tooltips within the GUI. Test the plugin across multiple EEGLAB versions (2019 onwards) to ensure compatibility. Create example signalJourney files for testing. Package the plugin for distribution through the EEGLAB plugin manager. Include README files and licensing information. Perform final bug fixes and optimizations based on testing results."
        }
      ]
    },
    {
      "id": 7,
      "title": "Develop Processing Pipeline Visualization Tools",
      "description": "Create tools to visualize processing pipelines described in signalJourney files as flowcharts or directed graphs.",
      "status": "deferred",
      "dependencies": [
        2,
        5
      ],
      "priority": "low",
      "details": "Implement visualization tools in both Python and MATLAB that: 1) Parse signalJourney files to extract processing steps and dependencies, 2) Generate visual representations of processing pipelines as flowcharts, 3) Highlight key parameters and transformations, 4) Allow interactive exploration of complex pipelines. For Python, use libraries like matplotlib, networkx, or plotly. For MATLAB, use built-in plotting capabilities or the GraphPlot toolbox. Include options for exporting visualizations as images or interactive HTML.",
      "testStrategy": "Test visualization with a range of signalJourney files, from simple to complex. Verify that all processing steps and relationships are correctly represented. Test interactive features and export functionality. Gather feedback from potential users on clarity and usefulness of visualizations.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement signalJourney File Parser",
          "description": "Create a parser module that can read and extract processing steps, dependencies, and parameters from signalJourney files in both Python and MATLAB.",
          "status": "pending",
          "dependencies": [],
          "details": "Develop a parser that: 1) Reads signalJourney file formats, 2) Extracts processing steps with their input/output relationships, 3) Identifies parameters and transformations, 4) Creates a structured data representation (graph data structure) that can be used by visualization components. For Python, use libraries like json, xml, or yaml depending on the signalJourney file format. For MATLAB, use appropriate file reading functions. Create a common internal representation that works across both platforms."
        },
        {
          "id": 2,
          "title": "Develop Basic Pipeline Graph Visualization in Python",
          "description": "Create the core visualization functionality in Python to render processing pipelines as directed graphs or flowcharts.",
          "status": "pending",
          "dependencies": [
            1
          ],
          "details": "Using the parser from subtask 1, implement visualization using networkx for graph structure and matplotlib/plotly for rendering. Include: 1) Node representation for processing steps, 2) Edge representation for data flow, 3) Basic layout algorithms (hierarchical, force-directed), 4) Node styling to represent different types of processing steps, 5) Edge styling to represent data dependencies. Implement functions to generate static visualizations with proper node placement, labels, and flow direction."
        },
        {
          "id": 3,
          "title": "Develop Basic Pipeline Graph Visualization in MATLAB",
          "description": "Create the core visualization functionality in MATLAB to render processing pipelines as directed graphs or flowcharts.",
          "status": "pending",
          "dependencies": [
            1
          ],
          "details": "Using the parser from subtask 1, implement visualization using MATLAB's built-in graph/digraph objects and plotting capabilities or the GraphPlot toolbox. Include: 1) Node representation for processing steps, 2) Edge representation for data flow, 3) Layout algorithms appropriate for pipeline visualization, 4) Node styling to represent different types of processing steps, 5) Edge styling to represent data dependencies. Ensure the MATLAB implementation provides similar visual output to the Python version while leveraging MATLAB-specific features."
        },
        {
          "id": 4,
          "title": "Implement Interactive Exploration Features",
          "description": "Enhance both Python and MATLAB visualizations with interactive features for exploring complex pipelines.",
          "status": "pending",
          "dependencies": [
            2,
            3
          ],
          "details": "For Python: 1) Use plotly or bokeh to create interactive visualizations, 2) Implement node hover information showing detailed parameters, 3) Add zoom and pan capabilities, 4) Create collapsible/expandable subgraphs for complex pipelines, 5) Add filtering options to focus on specific parts of the pipeline. For MATLAB: 1) Implement interactive graphs using MATLAB's interactive plotting features, 2) Add callbacks for node selection to display detailed information, 3) Create UI controls for adjusting visualization parameters, 4) Implement subgraph expansion/collapse functionality. Both implementations should allow users to interactively explore complex processing pipelines."
        },
        {
          "id": 5,
          "title": "Develop Export and Documentation Features",
          "description": "Add capabilities to export visualizations in various formats and create comprehensive documentation for both implementations.",
          "status": "pending",
          "dependencies": [
            4
          ],
          "details": "For both Python and MATLAB: 1) Implement export to static image formats (PNG, SVG, PDF), 2) For Python, add export to interactive HTML using plotly or bokeh, 3) For MATLAB, add export to interactive MATLAB figures, 4) Create comprehensive documentation including: usage examples, API reference, customization options, and example visualizations of common pipeline patterns. Include sample code for integrating the visualization tools into existing workflows. Create a unified user interface approach where possible between the two implementations to simplify learning and usage."
        }
      ]
    },
    {
      "id": 8,
      "title": "Integrate with BIDS-validator",
      "description": "Develop a plugin or extension for the BIDS-validator tool that validates signalJourney files within BIDS datasets.",
      "status": "deferred",
      "dependencies": [
        2
      ],
      "priority": "medium",
      "details": "Create an extension for the BIDS-validator that: 1) Recognizes signalJourney files in the derivatives directory, 2) Validates their structure against the signalJourney schema, 3) Checks BIDS-specific requirements like naming conventions and file placement, 4) Reports validation results within the BIDS-validator output. Follow the BIDS-validator extension API and development guidelines. Coordinate with the BIDS community for potential inclusion in the official validator. The extension should use the validation library from Task 2 for schema validation.",
      "testStrategy": "Test the extension with various BIDS datasets containing signalJourney files. Verify that validation correctly identifies valid and invalid files. Test integration with the main BIDS-validator workflow. Ensure proper reporting of validation results.",
      "subtasks": [
        {
          "id": 1,
          "title": "Research BIDS-validator extension API and architecture",
          "description": "Investigate the BIDS-validator extension mechanism, API requirements, and development guidelines to understand how to properly integrate a signalJourney validator.",
          "status": "pending",
          "dependencies": [],
          "details": "Study the BIDS-validator codebase on GitHub to understand its architecture. Document the extension points, API requirements, and development workflow. Create a technical design document outlining: 1) How extensions are registered with the validator, 2) The lifecycle of validation in BIDS-validator, 3) How to hook into the validation process, 4) How results are reported back to the main validator. Include code examples and references to relevant parts of the BIDS-validator documentation. Reach out to BIDS community members if documentation is insufficient."
        },
        {
          "id": 2,
          "title": "Develop core extension structure with signalJourney file detection",
          "description": "Create the basic extension structure that can be loaded by BIDS-validator and implement the file detection logic to recognize signalJourney files within BIDS datasets.",
          "status": "pending",
          "dependencies": [
            1
          ],
          "details": "Create the extension scaffold following BIDS-validator conventions identified in subtask 1. Implement file detection logic that: 1) Identifies files with .signaljourney.json extension in the derivatives directory, 2) Recognizes the appropriate directory structure for signalJourney files according to BIDS conventions, 3) Registers these files for validation. Test the extension with sample BIDS datasets containing signalJourney files to ensure proper detection. The extension should log detection events but not perform validation yet."
        },
        {
          "id": 3,
          "title": "Implement validation logic using the signalJourney validation library",
          "description": "Integrate the signalJourney validation library from Task 2 to validate the structure and content of detected signalJourney files against the schema.",
          "status": "pending",
          "dependencies": [
            2
          ],
          "details": "Import and integrate the signalJourney validation library developed in Task 2. Implement the validation logic that: 1) Takes detected signalJourney files and passes them to the validation library, 2) Validates file structure against the signalJourney schema, 3) Performs BIDS-specific validation checks including naming conventions, required fields, and file placement rules, 4) Collects validation results in a format compatible with BIDS-validator. Create unit tests to verify validation works correctly with both valid and invalid signalJourney files."
        },
        {
          "id": 4,
          "title": "Implement results reporting and finalize BIDS community integration",
          "description": "Format validation results according to BIDS-validator conventions, implement error reporting, and prepare the extension for potential inclusion in the official BIDS-validator.",
          "status": "pending",
          "dependencies": [
            3
          ],
          "details": "Implement result reporting that: 1) Formats validation errors and warnings according to BIDS-validator conventions, 2) Integrates with the BIDS-validator UI to display signalJourney-specific validation results, 3) Provides clear error messages and suggestions for fixing issues. Create comprehensive documentation for the extension including installation instructions, usage examples, and validation rules. Package the extension according to BIDS-validator guidelines. Create a pull request or proposal for the BIDS community to review the extension for potential inclusion in the official validator. Address feedback from the community review process."
        }
      ]
    },
    {
      "id": 9,
      "title": "Implement Quality Metrics Visualization Dashboard",
      "description": "Create a dashboard for visualizing and comparing quality metrics from signalJourney files.",
      "status": "deferred",
      "dependencies": [
        2,
        5,
        7
      ],
      "priority": "low",
      "details": "Develop a web-based dashboard using a framework like Dash, Streamlit, or Shiny that: 1) Loads and parses signalJourney files, 2) Extracts and displays quality metrics in an interactive dashboard, 3) Allows comparison of metrics across multiple files or processing approaches, 4) Provides visualizations like bar charts, histograms, and heatmaps for different metric types. Include filtering and sorting capabilities. Support both standalone usage and integration with existing platforms. Provide documentation for installation and usage.",
      "testStrategy": "Test the dashboard with various signalJourney files containing different quality metrics. Verify that all metrics are correctly extracted and displayed. Test comparison functionality with multiple files. Evaluate usability with potential users and gather feedback on the interface and visualizations.",
      "subtasks": [
        {
          "id": 1,
          "title": "Create data loading and parsing module",
          "description": "Develop a module that can load and parse signalJourney files to extract quality metrics data",
          "status": "pending",
          "dependencies": [],
          "details": "Implement a Python module that: 1) Accepts signalJourney files as input, 2) Parses the file structure to extract all quality metrics, 3) Organizes the data into a standardized format (e.g., pandas DataFrame) suitable for visualization, 4) Handles different file formats and versions gracefully with appropriate error handling, 5) Includes utility functions to extract specific metric categories. The module should be independent of the visualization framework to allow for reuse."
        },
        {
          "id": 2,
          "title": "Set up basic dashboard framework",
          "description": "Initialize the web dashboard framework and create the basic application structure",
          "status": "pending",
          "dependencies": [
            1
          ],
          "details": "Select and set up one of the recommended frameworks (Dash, Streamlit, or Shiny). Create the basic application structure including: 1) Project directory organization, 2) Required dependencies in requirements.txt, 3) Main application file with initialization code, 4) Basic layout with placeholders for visualization components, 5) Integration with the data loading module from subtask 1. Ensure the application can be launched locally with minimal configuration."
        },
        {
          "id": 3,
          "title": "Implement core visualization components",
          "description": "Develop the primary visualization components for displaying individual quality metrics",
          "status": "pending",
          "dependencies": [
            1,
            2
          ],
          "details": "Create visualization components that display quality metrics in various formats: 1) Bar charts for comparing discrete metrics, 2) Histograms for distribution analysis, 3) Heatmaps for correlation or time-series data, 4) Summary statistics tables. Each component should: accept standardized data from the parser module, include appropriate labels and legends, use a consistent color scheme, and handle edge cases like missing data. Implement these as modular, reusable components that can be arranged on the dashboard."
        },
        {
          "id": 4,
          "title": "Add interactive comparison features",
          "description": "Implement functionality to compare metrics across multiple files or processing approaches",
          "status": "pending",
          "dependencies": [
            2,
            3
          ],
          "details": "Enhance the dashboard with comparison capabilities: 1) Add file upload or selection interface for multiple signalJourney files, 2) Implement side-by-side visualization of metrics from different files, 3) Create differential views that highlight changes or improvements between files, 4) Add filtering controls to focus on specific metrics or value ranges, 5) Implement sorting functionality to rank files by specific metrics. Ensure the UI remains responsive even when comparing multiple large files."
        },
        {
          "id": 5,
          "title": "Finalize dashboard with documentation and integration options",
          "description": "Complete the dashboard with export features, documentation, and integration capabilities",
          "status": "pending",
          "dependencies": [
            3,
            4
          ],
          "details": "Finalize the dashboard with: 1) Data and visualization export functionality (CSV, PNG, PDF), 2) Comprehensive user documentation including installation instructions, usage examples, and explanation of metrics, 3) Developer documentation for extending the dashboard, 4) Configuration options for standalone usage or integration with existing platforms (API endpoints, embedding options), 5) Responsive design for different screen sizes, 6) Final testing across different browsers and platforms. Package everything for easy deployment with Docker or similar containerization."
        }
      ]
    },
    {
      "id": 10,
      "title": "Create Comprehensive Documentation and Tutorials",
      "description": "Develop detailed documentation, tutorials, and examples for the signalJourney specification and associated tools.",
      "status": "done",
      "dependencies": [
        1,
        2,
        3,
        4,
        5
      ],
      "priority": "high",
      "details": "Create comprehensive documentation that includes: 1) Detailed specification guide with field descriptions and examples, 2) Tutorials for creating signalJourney files manually and with tools, 3) User guides for all developed tools (Python library, MATLAB tools, EEGLAB plugin, etc.), 4) Examples of common use cases with sample code, 5) Best practices for integration with BIDS datasets, 6) FAQ and troubleshooting section. Use a documentation framework like Sphinx or MkDocs. Host documentation on Read the Docs or GitHub Pages. Include interactive examples where possible. Explicitly discuss BIDS integration strategies, including the use of .bidsignore and the possibility of root-level vs. derivative-level signalJourney files for dataset-wide pipelines.",
      "testStrategy": "Review documentation for accuracy, completeness, and clarity. Have users with different levels of expertise test the tutorials and provide feedback. Verify that all tools and features are adequately documented. Test that code examples work as expected.",
      "subtasks": [
        {
          "id": 1,
          "title": "Set up documentation framework and structure",
          "description": "Select and configure a documentation framework (Sphinx or MkDocs) and establish the overall structure for the signalJourney documentation.",
          "status": "done",
          "dependencies": [],
          "details": "Choose between Sphinx (Python-focused) or MkDocs (Markdown-based) based on team preferences. Set up the initial repository with proper configuration. Create a comprehensive structure including sections for: specification guide, tutorials, user guides for each tool, examples, BIDS integration, and FAQ/troubleshooting. Configure automated builds and prepare for hosting on Read the Docs or GitHub Pages. Establish style guidelines and templates for consistent documentation."
        },
        {
          "id": 2,
          "title": "Create detailed signalJourney specification documentation",
          "description": "Develop the core specification documentation with complete field descriptions, validation rules, and multiple examples.",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "Document the complete signalJourney specification including: all required and optional fields with detailed descriptions, data types, and constraints; validation rules and schema information; multiple examples showing different use cases (simple to complex); versioning information and compatibility notes; relationship to other standards (especially BIDS). Include diagrams showing the structure of signalJourney files and their relationships. Add interactive examples if the documentation platform supports it."
        },
        {
          "id": 3,
          "title": "Develop tutorials for creating and working with signalJourney files",
          "description": "Create step-by-step tutorials for manually creating signalJourney files and using the various tools to generate them.",
          "status": "done",
          "dependencies": [
            1,
            2
          ],
          "details": "Develop multiple tutorials including: step-by-step guide for manually creating signalJourney files; tutorial for using the Python library to generate files; tutorial for using MATLAB tools; tutorial for using the EEGLAB plugin; guide for validating signalJourney files; tutorial for converting existing metadata to signalJourney format. Each tutorial should include complete code examples, screenshots where appropriate, and expected outcomes. Structure tutorials from basic to advanced usage patterns."
        },
        {
          "id": 4,
          "title": "Write comprehensive user guides for all tools",
          "description": "Create detailed user guides for each tool in the signalJourney ecosystem (Python library, MATLAB tools, EEGLAB plugin, etc.).",
          "status": "done",
          "dependencies": [
            1
          ],
          "details": "For each tool (Python library, MATLAB tools, EEGLAB plugin, and any others), create a comprehensive user guide including: installation instructions; API reference with function/method documentation; configuration options; common usage patterns; performance considerations; troubleshooting section. Include code examples for all major functions. Document version compatibility requirements. Add diagrams showing the architecture of each tool and how they interact with signalJourney files."
        },
        {
          "id": 5,
          "title": "Create examples and best practices documentation",
          "description": "Develop a collection of examples covering common use cases and best practices, especially for BIDS integration.",
          "status": "done",
          "dependencies": [
            2,
            3,
            4
          ],
          "details": "Create a comprehensive examples section including: complete working examples for common research scenarios; best practices for organizing signalJourney files; guidelines for integrating with BIDS datasets (with specific examples); examples showing integration with analysis pipelines; performance optimization tips; versioning and file management recommendations. Include downloadable sample code and data files. Document common pitfalls and how to avoid them. Create decision trees to help users determine the best approach for their specific use case."
        },
        {
          "id": 6,
          "title": "Develop FAQ, troubleshooting guide, and publish documentation",
          "description": "Create a comprehensive FAQ and troubleshooting section, finalize all documentation, and publish to the selected hosting platform.",
          "status": "done",
          "dependencies": [
            2,
            3,
            4,
            5
          ],
          "details": "Compile a comprehensive FAQ based on anticipated user questions and early feedback. Create a detailed troubleshooting guide addressing common errors and issues. Review and edit all documentation for consistency, completeness, and clarity. Implement cross-references between related sections. Add search functionality and proper indexing. Deploy the documentation to the selected hosting platform (Read the Docs or GitHub Pages). Set up processes for maintaining and updating documentation as the specification and tools evolve. Create a feedback mechanism for users to report documentation issues or request clarifications."
        },
        {
          "id": 7,
          "title": "Document BIDS integration strategies",
          "description": "Create detailed documentation on BIDS integration approaches for signalJourney files",
          "status": "done",
          "dependencies": [
            2,
            5
          ],
          "details": "Develop comprehensive documentation specifically addressing BIDS integration strategies, including: detailed explanation of using .bidsignore to manage signalJourney files within BIDS datasets; comparison of root-level vs. derivative-level placement of signalJourney files for dataset-wide pipelines; examples of both approaches with pros and cons; recommendations for different use cases; compatibility considerations with BIDS validators; examples of directory structures showing proper integration. Include diagrams illustrating the different integration approaches and their implications for data organization and analysis workflows."
        }
      ]
    },
    {
      "id": 11,
      "title": "Refactor JSON Schema into Modular Structure with $ref References",
      "description": "Restructure the signalJourney.schema.json file by breaking it down into smaller, reusable schema components organized in definitions/ and extensions/ subdirectories, following the structure defined in schema-org.mdc.",
      "details": "This task involves refactoring the monolithic JSON schema file (schema/signalJourney.schema.json) into a more maintainable, modular structure:\n\n1. Create two new subdirectories:\n   - `schema/definitions/` - For core schema components that define the base data structures\n   - `schema/extensions/` - For domain-specific extensions to the core schema\n\n2. Analyze the current schema structure and the organization rules defined in `.cursor/rules/schema-org.mdc`\n\n3. Break down the schema based on logical components. For example:\n   - Common types (e.g., coordinates, timestamps) should go in definitions/\n   - Domain-specific schemas should go in extensions/\n   - Each component should be in its own file with a descriptive name\n\n4. Update the main schema file (signalJourney.schema.json) to:\n   - Keep the top-level schema structure intact\n   - Replace inline schema definitions with $ref references to the appropriate files\n   - Use proper JSON Schema $ref syntax (e.g., \"$ref\": \"./definitions/commonType.schema.json\")\n\n5. Ensure all paths in $ref are correctly relative to the main schema file\n\n6. Maintain backward compatibility - the refactored schema should validate the same documents as the original\n\n7. Update any documentation that references the schema structure\n\nThe goal is to improve maintainability and reusability while keeping the same validation behavior.\n\n**Git Workflow:**\n- Before starting, create a feature branch (e.g., `feature/11-schema-refactor`)\n- After implementation and testing, create a PR targeting `main`\n- Add a comment tagging @neuromechanist for review, mentioning this task ID",
      "testStrategy": "To verify the refactoring has been implemented correctly:\n\n1. Schema Validation:\n   - Use a JSON Schema validator (like ajv) to validate that the refactored schema is syntactically correct\n   - Verify all $ref paths resolve correctly without errors\n\n2. Functional Equivalence Testing:\n   - Create a test suite with sample JSON documents that were valid against the original schema\n   - Verify these same documents validate correctly against the refactored schema\n   - Include edge cases that test various parts of the schema\n\n3. Regression Testing:\n   - Test documents that should fail validation against the original schema\n   - Verify they still fail validation against the refactored schema for the same reasons\n\n4. Structure Verification:\n   - Confirm the directory structure matches requirements (definitions/ and extensions/ subdirectories exist)\n   - Verify schema files are appropriately placed based on their purpose\n   - Check that no schema components are duplicated across files\n\n5. Manual Review:\n   - Conduct a code review to ensure the refactoring follows the structure defined in schema-org.mdc\n   - Verify naming conventions are consistent and intuitive\n\n6. Integration Testing:\n   - If any applications consume this schema, test them with the refactored version to ensure compatibility",
      "status": "done",
      "dependencies": [],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Analyze Schema Structure and Create Directory Framework",
          "description": "Analyze the current signalJourney.schema.json file to identify logical components for modularization and create the required directory structure for the refactored schema.",
          "dependencies": [],
          "details": "1. Create the required directories: `schema/definitions/` and `schema/extensions/`\n2. Analyze the current schema structure in signalJourney.schema.json to identify:\n   - Common/reusable types (timestamps, coordinates, identifiers)\n   - Core domain objects (users, journeys, signals)\n   - Domain-specific extensions\n   - Repeated patterns that can be extracted\n3. Map each component to either definitions/ (for core components) or extensions/ (for domain-specific extensions)\n4. Create a schema mapping document that outlines:\n   - Which components will be extracted\n   - The file naming convention (use descriptive names with .schema.json extension)\n   - The dependency relationships between components\n5. Review the organization rules in .cursor/rules/schema-org.mdc to ensure compliance\n6. Test the directory structure by ensuring proper permissions and accessibility\n\nTesting approach: Verify directory structure exists and is accessible, and that the mapping document is complete and follows best practices for JSON Schema modularization.\n\n<info added on 2025-05-02T17:52:19.899Z>\n# Implementation Plan (Iteration 1)\n\n## Schema Analysis Strategy\n- Use `jq` or a JSON schema visualization tool to analyze the current schema structure\n- Create a dependency graph to visualize relationships between schema components\n- Identify circular references that need special handling during modularization\n\n## File Organization Details\n- **Definitions Directory**: Store reusable components with high cohesion\n  - Use subdirectories for logical grouping if more than 10 definition files emerge\n  - Consider `common/` subdirectory for truly generic types (timestamps, coordinates)\n  - Consider `core/` subdirectory for domain-specific but widely reused types\n- **Extensions Directory**: Organize by domain/purpose with clear namespacing\n\n## Naming Conventions\n- Use kebab-case for filenames (e.g., `processing-step.schema.json`)\n- Use descriptive prefixes for related components (e.g., `metrics-quality.schema.json`, `metrics-summary.schema.json`)\n- Include version in filename if supporting multiple versions simultaneously\n\n## Reference Strategy\n- Use JSON Pointers with relative paths for internal references\n- Consider using JSON Schema `$id` for complex references\n- Document reference patterns in a README.md file\n\n## Schema Mapping Document Template\n```markdown\n# Schema Component Mapping\n\n## Core Components\n| Component | Source Location | Target File | Dependencies |\n|-----------|----------------|-------------|--------------|\n| Processing Step | definitions.processingStep | definitions/processing-step.schema.json | softwareDetails, parameter |\n...\n\n## Extensions\n| Extension | Purpose | Target File | Dependencies |\n|-----------|---------|-------------|--------------|\n| EEG | EEG-specific metadata | extensions/eeg.schema.json | None |\n...\n```\n\n## Validation Strategy\n- Create a script to validate that all references resolve correctly after modularization\n- Test with both absolute and relative paths to ensure portability\n</info added on 2025-05-02T17:52:19.899Z>",
          "status": "done",
          "parentTaskId": 11
        },
        {
          "id": 2,
          "title": "Extract Core Schema Definitions into Separate Files",
          "description": "Extract the core schema components identified in the analysis phase into separate files in the definitions/ directory, following JSON Schema best practices.",
          "dependencies": [
            1
          ],
          "details": "1. For each core component identified in subtask 1:\n   - Create a new file in the definitions/ directory with a descriptive name (e.g., definitions/coordinate.schema.json)\n   - Copy the relevant schema section from signalJourney.schema.json\n   - Ensure each file has proper schema metadata ($schema, title, description)\n   - Add appropriate documentation in each file\n2. For each extracted component:\n   - Ensure it's a complete, valid JSON Schema\n   - Include a descriptive title and description\n   - Use $defs for any internal subschemas that are only relevant within that component\n   - Ensure any internal references use proper JSON Schema $ref syntax\n3. Validate each extracted schema file individually using a JSON Schema validator\n4. Document any dependencies between schema files for later reference\n\nTesting approach: Validate each extracted schema file individually using a tool like ajv or jsonschema to ensure it's a valid JSON Schema document. Create small test JSON documents that should validate against each schema to verify correctness.\n\n<info added on 2025-05-02T17:52:51.616Z>\n# Implementation Plan (Iteration 1)\n\n## File Structure and Naming Conventions\n- Use `.schema.json` extension for all schema files for clarity\n- Organize files with logical prefixes (e.g., `core-`, `type-`, etc.) if needed for grouping\n\n## Reference Management\n- When extracting schemas, use absolute URIs for external references: `{\"$ref\": \"https://json-schema.org/draft/2020-12/schema\"}`\n- For internal references between definition files, use relative paths with proper JSON Pointer syntax: `{\"$ref\": \"./softwareDetails.schema.json#\"}`\n- Consider using JSON Schema `$id` fields with URN format for each definition: `\"$id\": \"urn:signaljourney:schema:softwareDetails\"`\n\n## Schema Metadata Template\n```json\n{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"urn:signaljourney:schema:componentName\",\n  \"title\": \"Component Name\",\n  \"description\": \"Detailed description of this component's purpose\",\n  \"type\": \"object\",\n  \"properties\": {\n    // Properties go here\n  },\n  \"required\": [\"requiredProperty1\", \"requiredProperty2\"]\n}\n```\n\n## Dependency Documentation\nCreate a `dependencies.md` file in the definitions directory that maps:\n- Which schema files depend on which others\n- The nature of each dependency (composition, inheritance, etc.)\n- Any circular dependencies that need special handling\n\n## Validation Script\nCreate a Node.js script (`validate-schemas.js`) that:\n```javascript\nconst Ajv = require('ajv');\nconst fs = require('fs');\nconst path = require('path');\n\nconst ajv = new Ajv({allErrors: true});\nconst definitionsDir = path.join(__dirname, 'definitions');\n\n// Load and validate each schema\nfs.readdirSync(definitionsDir)\n  .filter(file => file.endsWith('.schema.json'))\n  .forEach(file => {\n    const schema = JSON.parse(fs.readFileSync(path.join(definitionsDir, file)));\n    const valid = ajv.validateSchema(schema);\n    \n    if (!valid) {\n      console.error(`Schema validation failed for ${file}:`, ajv.errorsText());\n    } else {\n      console.log(`✓ Schema ${file} is valid`);\n    }\n  });\n```\n</info added on 2025-05-02T17:52:51.616Z>",
          "status": "done",
          "parentTaskId": 11
        },
        {
          "id": 3,
          "title": "Extract Domain-Specific Extensions into Separate Files",
          "description": "Extract domain-specific schema extensions identified in the analysis phase into separate files in the extensions/ directory, following JSON Schema best practices.",
          "dependencies": [
            1
          ],
          "details": "1. For each domain-specific extension identified in subtask 1:\n   - Create a new file in the extensions/ directory with a descriptive name (e.g., extensions/marketingData.schema.json)\n   - Copy the relevant schema section from signalJourney.schema.json\n   - Ensure each file has proper schema metadata ($schema, title, description)\n   - Add appropriate documentation in each file\n2. For each extracted extension:\n   - Ensure it's a complete, valid JSON Schema\n   - Include a descriptive title and description\n   - Use $ref to reference any core definitions from the definitions/ directory\n   - Avoid circular references between extensions\n3. Validate each extension schema file individually\n4. Document any dependencies on core definitions or other extensions\n\nTesting approach: Validate each extension schema file individually using a JSON Schema validator. Create test JSON documents that should validate against each extension schema to verify correctness. Test any references to core definitions to ensure they resolve correctly.\n\n<info added on 2025-05-02T17:55:54.332Z>\n# Implementation Details for Domain-Specific Extensions\n\n## File Structure and Naming Conventions\n- Use kebab-case for filenames (e.g., `eeg-metadata.schema.json` instead of `eegMetadata.schema.json`)\n- Follow a consistent naming pattern: `{domain}-{concept}.schema.json`\n- Create an `index.js` file in the extensions directory to export all extensions for easier importing\n\n## Schema Design Guidelines\n- Include `$id` fields with absolute URIs (e.g., `https://signaljourney.org/schema/extensions/eeg.schema.json`)\n- Use semantic versioning in schemas with `$version` property\n- Implement `allOf` to compose schemas rather than duplicating properties\n- Add `examples` array with at least one valid instance for each extension\n\n## Reference Implementation\n```json\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"$id\": \"https://signaljourney.org/schema/extensions/eeg.schema.json\",\n  \"title\": \"EEG Extension Schema\",\n  \"description\": \"Schema extension for EEG-specific metadata in Signal Journey\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"samplingRate\": {\n      \"type\": \"number\",\n      \"description\": \"Sampling rate in Hz\",\n      \"minimum\": 0\n    },\n    \"channelCount\": {\n      \"type\": \"integer\",\n      \"description\": \"Number of EEG channels\",\n      \"minimum\": 1\n    }\n  },\n  \"examples\": [\n    {\n      \"samplingRate\": 256,\n      \"channelCount\": 64,\n      \"montage\": \"10-20\"\n    }\n  ]\n}\n```\n\n## Testing Strategy\n- Create a test suite with both valid and invalid examples for each extension\n- Test cross-extension references with complex nested structures\n- Implement JSON Schema validation in CI pipeline using Ajv or similar validator\n- Create documentation generation script that extracts examples from schemas\n</info added on 2025-05-02T17:55:54.332Z>",
          "status": "done",
          "parentTaskId": 11
        },
        {
          "id": 4,
          "title": "Update Main Schema with $ref References",
          "description": "Refactor the main signalJourney.schema.json file to replace inline schema definitions with $ref references to the extracted component files, maintaining the same validation behavior.",
          "dependencies": [
            2,
            3
          ],
          "details": "1. Create a backup of the original signalJourney.schema.json file\n2. Update the main schema file to:\n   - Keep the top-level schema structure intact (type, title, description, etc.)\n   - Replace each extracted component with a $ref to the appropriate file\n   - Use proper relative paths in $ref references (e.g., \"$ref\": \"./definitions/user.schema.json\")\n   - Maintain any required fields and validation rules\n3. For each $ref:\n   - Ensure the path is correctly relative to the main schema file\n   - Verify that the referenced schema exists\n   - Check that the reference resolves correctly\n4. Validate the updated main schema using a JSON Schema validator that supports $ref resolution\n5. Test the schema against sample documents that were valid against the original schema\n\nTesting approach: Use a JSON Schema validator that supports $ref resolution (like ajv) to validate the refactored schema. Test with a comprehensive set of valid and invalid sample documents to ensure the validation behavior remains unchanged from the original schema.\n\n<info added on 2025-05-02T17:56:35.206Z>\n## Implementation Plan (Iteration 1)\n\n1. **Read Source:** Load `schema/signalJourney.schema.json`.\n2. **Update `properties.processingSteps`:** Change `items.$ref` to point to `\"definitions/processingStep.json\"`.\n3. **Update `properties.summaryMetrics`:** Remove existing `type` and `description`. Change the property to be just `{\"$ref\": \"definitions/qualityMetricsObject.json\"}`.\n4. **Update `properties.extensions`:** Remove existing `type`, `description`, `properties`, and `additionalProperties`. Change the property to be just `{\"$ref\": \"extensions/extensionsContainer.json\"}`.\n5. **Remove `definitions`:** Delete the entire `definitions` object and its contents from the end of the file.\n6. **Format and Validate:** Ensure the resulting JSON is well-formatted and structurally valid (though full schema validation comes later).\n7. **Next Steps:** Proceed to subtask 11.5 for final validation and documentation updates.\n\n### Implementation Notes\n\n```javascript\n// Example Node.js implementation for updating the schema\nconst fs = require('fs');\nconst path = require('path');\n\n// Create backup\nconst schemaPath = path.join(__dirname, 'schema/signalJourney.schema.json');\nconst backupPath = path.join(__dirname, 'schema/signalJourney.schema.json.bak');\nfs.copyFileSync(schemaPath, backupPath);\n\n// Read and parse schema\nconst schema = JSON.parse(fs.readFileSync(schemaPath, 'utf8'));\n\n// Update references\nschema.properties.processingSteps.items = { \"$ref\": \"./definitions/processingStep.json\" };\nschema.properties.summaryMetrics = { \"$ref\": \"./definitions/qualityMetricsObject.json\" };\nschema.properties.extensions = { \"$ref\": \"./extensions/extensionsContainer.json\" };\n\n// Remove definitions section\ndelete schema.definitions;\n\n// Write updated schema\nfs.writeFileSync(\n  schemaPath, \n  JSON.stringify(schema, null, 2),\n  'utf8'\n);\n```\n\n### Potential Issues to Watch For\n\n- **Path Resolution**: Ensure paths are correct relative to the main schema file location\n- **Circular References**: Check for any circular dependencies that might have been created\n- **Schema ID Conflicts**: Verify that `$id` properties don't conflict between schemas\n- **JSON Pointer Syntax**: If using complex references with JSON pointers, ensure correct syntax (e.g., `\"$ref\": \"./definitions/processingStep.json#/definitions/specificPart\"`)\n\n### Validation Strategy\n\nUse a tool like `ajv-cli` to validate the refactored schema:\n\n```bash\n# Install validator\nnpm install -g ajv-cli\n\n# Validate schema\najv compile -s schema/signalJourney.schema.json\n\n# Test with sample documents\najv validate -s schema/signalJourney.schema.json -d \"samples/*.json\"\n```\n</info added on 2025-05-02T17:56:35.206Z>",
          "status": "done",
          "parentTaskId": 11
        },
        {
          "id": 5,
          "title": "Validate Refactored Schema and Update Documentation",
          "description": "Perform comprehensive validation of the refactored schema structure to ensure backward compatibility and update any documentation that references the schema structure.",
          "dependencies": [
            4
          ],
          "details": "1. Perform comprehensive validation:\n   - Validate the entire schema structure using a JSON Schema validator with $ref support\n   - Test with a diverse set of valid and invalid documents from production or test environments\n   - Verify that documents that were valid against the original schema are still valid\n   - Verify that documents that were invalid against the original schema are still invalid\n2. Check for any circular references or resolution issues in the schema structure\n3. Update documentation:\n   - Update any README files or documentation that describes the schema structure\n   - Document the new modular approach and directory structure\n   - Create a schema diagram showing the relationships between components\n   - Add comments in the schema files explaining the purpose and usage of each component\n4. Create a pull request:\n   - Create a feature branch named 'feature/11-schema-refactor'\n   - Commit all changes with descriptive commit messages\n   - Create a PR targeting main\n   - Add a comment tagging @neuromechanist for review, mentioning task ID 11\n   - Include a summary of changes and validation results\n\nTesting approach: Use automated tests to validate the refactored schema against a comprehensive test suite of valid and invalid documents. Manually review the schema structure and documentation for clarity and correctness. Have another team member review the changes to ensure the modular structure is intuitive and follows best practices.\n\n<info added on 2025-05-02T17:57:03.405Z>\n## Implementation Notes (Iteration 1)\n\n### Validation Strategy\n- Use `ajv` or similar JSON Schema validator that supports draft-07 and $ref resolution\n- Create a validation script that:\n  - Recursively loads all schema files\n  - Resolves references using a custom resolver that handles local file paths\n  - Tests schema compilation to catch structural errors\n- Implement specific backward compatibility tests:\n  - Compare validation results between old and new schemas using identical test data\n  - Log any discrepancies for investigation\n\n### Documentation Enhancement\n- Add a \"Schema Migration Guide\" section explaining:\n  - How to update references from monolithic to modular schema\n  - Breaking changes (if any) and mitigation strategies\n  - Performance considerations with the new reference structure\n- Include examples of how to reference specific schema components\n- Document the rationale behind the modular structure (maintainability, reuse, etc.)\n\n### Schema Diagram Generation\n- Use a tool like `jsonschema2diagram` to automatically generate visual representations\n- Create both a high-level overview diagram and detailed component diagrams\n- Include these diagrams in both documentation and as standalone SVG files in the repo\n\n### Circular Reference Detection\n- Implement a custom script that builds a directed graph of schema references\n- Use cycle detection algorithms to identify any circular dependencies\n- Document any intentional circular references with justification\n</info added on 2025-05-02T17:57:03.405Z>",
          "status": "done",
          "parentTaskId": 11
        }
      ]
    },
    {
      "id": 12,
      "title": "Migrate Sphinx Documentation to MkDocs with Material Theme",
      "description": "Convert the existing Sphinx documentation in the docs/ directory to MkDocs using the Material theme and Mkdocstrings plugin, following the provided guidelines.",
      "details": "This task involves a complete migration from Sphinx to MkDocs:\n\n**Git Workflow**:\n- Before starting, create a feature branch (e.g., `feature/12-mkdocs-migration`)\n- After implementation and testing, create a PR targeting `main`\n- Add a comment tagging @neuromechanist for review, mentioning this task ID\n\n1. **Convert RST to Markdown**:\n   - Convert all .rst files in the docs/ directory to Markdown (.md) format\n   - Ensure proper conversion of Sphinx-specific directives to Markdown equivalents\n   - Maintain all existing content, code examples, and formatting\n\n2. **Setup MkDocs Configuration**:\n   - Create a `mkdocs.yml` file in the project root\n   - Configure the Material theme with appropriate settings (colors, fonts, navigation features)\n   - Follow the guidelines specified in `.cursor/rules/mkdocs.mdc`\n\n3. **Configure Plugins**:\n   - Set up mkdocstrings for automatic API documentation generation\n   - Configure mkdocstrings to properly parse Python docstrings\n   - Add any other necessary plugins (e.g., search, navigation, etc.)\n\n4. **Restructure Navigation**:\n   - Create a logical navigation structure in mkdocs.yml\n   - Ensure all existing documentation sections are properly represented\n   - Implement proper nesting and organization of documentation pages\n\n5. **Update Dependencies**:\n   - Add mkdocs, mkdocs-material, and mkdocstrings to pyproject.toml\n   - Specify appropriate version constraints for each dependency\n   - Include any other required MkDocs plugins\n\n6. **Documentation Build Process**:\n   - Update any existing documentation build scripts or CI/CD pipelines\n   - Ensure the documentation can be built without errors\n   - Create a simple guide for local documentation building",
      "testStrategy": "To verify successful migration:\n\n1. **Build Verification**:\n   - Run `mkdocs build` and ensure it completes without errors\n   - Run `mkdocs serve` and verify the documentation is accessible locally\n\n2. **Content Validation**:\n   - Compare the rendered MkDocs site with the original Sphinx documentation\n   - Verify all pages from the original documentation exist in the new structure\n   - Check that all images, tables, and code blocks render correctly\n\n3. **Navigation Testing**:\n   - Test all navigation links to ensure they work correctly\n   - Verify that the navigation structure matches the planned hierarchy\n   - Test on both desktop and mobile viewports to ensure responsive design\n\n4. **API Documentation**:\n   - Verify that mkdocstrings correctly generates API documentation\n   - Compare generated API docs with the original Sphinx autodoc output\n   - Ensure all classes, methods, and functions are properly documented\n\n5. **Search Functionality**:\n   - Test the search feature with various keywords\n   - Verify that search results are relevant and comprehensive\n\n6. **Dependency Verification**:\n   - Confirm that all added dependencies in pyproject.toml are correct\n   - Verify that a fresh install with the updated dependencies works correctly\n\n7. **Cross-browser Testing**:\n   - Test the documentation in Chrome, Firefox, and Safari\n   - Verify that the Material theme renders correctly in all browsers",
      "status": "pending",
      "dependencies": [
        11
      ],
      "priority": "medium",
      "subtasks": [
        {
          "id": 1,
          "title": "Convert RST Documentation to Markdown Format",
          "description": "Convert all existing Sphinx RST files to Markdown format while preserving content structure, formatting, and special directives.",
          "dependencies": [],
          "details": "Implementation steps:\n1. Install conversion tools: `pip install rst2myst pandoc`\n2. Create a backup of the original docs/ directory\n3. Use rst2myst for structural conversion: `rst2myst convert --replace-files -dr any $(find docs -name '*.rst')`\n4. For complex formatting cases, use pandoc as a fallback: `find docs -name '*.rst' -exec pandoc -f rst -t markdown -o {}.md {} \\;`\n5. Manually review and fix any conversion issues, particularly:\n   - Cross-references (replace Sphinx `:ref:` with MkDocs-style links)\n   - Code blocks and their syntax highlighting\n   - Tables and complex formatting\n   - Image references and paths\n6. Rename all converted files with .md extension\n7. Test by viewing the markdown files in a markdown previewer\n\nTesting approach:\n- Use a markdown linter to check for syntax errors\n- Visually compare original RST and converted MD files for content preservation\n- Create a checklist of special Sphinx directives and verify their proper conversion",
          "status": "pending",
          "parentTaskId": 12
        },
        {
          "id": 2,
          "title": "Create MkDocs Configuration with Material Theme",
          "description": "Set up the MkDocs configuration file with Material theme settings according to project guidelines.",
          "dependencies": [
            1
          ],
          "details": "Implementation steps:\n1. Create a `mkdocs.yml` file in the project root\n2. Configure basic site information:\n   ```yaml\n   site_name: [Project Name]\n   site_url: [Project URL]\n   repo_url: [Repository URL]\n   repo_name: [Repository Name]\n   ```\n3. Set up Material theme with appropriate features:\n   ```yaml\n   theme:\n     name: material\n     palette:\n       # Configure colors according to .cursor/rules/mkdocs.mdc\n       primary: indigo\n       accent: indigo\n     features:\n       - navigation.tabs\n       - navigation.indexes\n       - navigation.top\n       - search.highlight\n       - search.suggest\n   ```\n4. Configure Markdown extensions:\n   ```yaml\n   markdown_extensions:\n     - admonition\n     - codehilite\n     - pymdownx.highlight\n     - pymdownx.superfences\n     - pymdownx.tabbed\n     - toc:\n         permalink: true\n   ```\n5. Follow the specific guidelines in `.cursor/rules/mkdocs.mdc` for any additional theme configuration\n\nTesting approach:\n- Run `mkdocs serve` to preview the site with the basic configuration\n- Verify theme appearance matches requirements\n- Check that basic navigation works correctly",
          "status": "pending",
          "parentTaskId": 12
        },
        {
          "id": 3,
          "title": "Configure MkDocs Plugins and API Documentation",
          "description": "Set up mkdocstrings and other necessary plugins for API documentation generation and enhanced functionality.",
          "dependencies": [
            2
          ],
          "details": "Implementation steps:\n1. Update the mkdocs.yml file to include required plugins:\n   ```yaml\n   plugins:\n     - search\n     - mkdocstrings:\n         handlers:\n           python:\n             options:\n               show_source: true\n               show_root_heading: true\n               heading_level: 2\n               docstring_style: google\n     - git-revision-date-localized:\n         enable_creation_date: true\n   ```\n2. Create an API documentation page structure:\n   - Create an `api/` directory in the docs folder\n   - Add index.md files for each module to document\n   - Use mkdocstrings syntax to generate API docs:\n     ```markdown\n     # API Reference\n     \n     ::: module.name\n         options:\n           show_source: true\n     ```\n3. Configure any additional plugins needed (e.g., for diagrams, versioning)\n4. Test API documentation generation with sample modules\n\nTesting approach:\n- Run `mkdocs build --strict` to check for plugin configuration errors\n- Verify API documentation is correctly generated from docstrings\n- Test search functionality to ensure it indexes API documentation",
          "status": "pending",
          "parentTaskId": 12
        },
        {
          "id": 4,
          "title": "Create Navigation Structure and Update Dependencies",
          "description": "Define the navigation hierarchy in mkdocs.yml and update project dependencies to include MkDocs and required plugins.",
          "dependencies": [
            1,
            2,
            3
          ],
          "details": "Implementation steps:\n1. Create a logical navigation structure in mkdocs.yml:\n   ```yaml\n   nav:\n     - Home: index.md\n     - User Guide:\n       - Installation: user/installation.md\n       - Configuration: user/configuration.md\n       # Add all converted documentation pages with proper hierarchy\n     - API Reference:\n       - Overview: api/index.md\n       # Add all API documentation pages\n     - Development:\n       - Contributing: development/contributing.md\n       # Add developer documentation\n   ```\n2. Ensure all existing documentation sections from Sphinx are represented\n3. Implement proper nesting and organization matching the original structure\n4. Update project dependencies in pyproject.toml:\n   ```toml\n   [project.optional-dependencies]\n   docs = [\n     \"mkdocs>=1.4.0\",\n     \"mkdocs-material>=9.0.0\",\n     \"mkdocstrings>=0.20.0\",\n     \"mkdocstrings-python>=0.8.0\",\n     \"pymdown-extensions>=9.0\",\n     \"mkdocs-git-revision-date-localized-plugin>=1.1.0\"\n   ]\n   ```\n5. Create a docs/requirements.txt file with the same dependencies for CI/CD\n\nTesting approach:\n- Run `mkdocs serve` and verify all pages are accessible through navigation\n- Check that the navigation structure matches the original Sphinx documentation\n- Install dependencies in a clean environment to verify they resolve correctly",
          "status": "pending",
          "parentTaskId": 12
        },
        {
          "id": 5,
          "title": "Update Build Process and Documentation",
          "description": "Update build scripts, CI/CD pipelines, and create documentation for the new MkDocs setup.",
          "dependencies": [
            1,
            2,
            3,
            4
          ],
          "details": "Implementation steps:\n1. Create a simple shell script for local documentation building:\n   ```bash\n   #!/bin/bash\n   # build_docs.sh\n   pip install -e \".[docs]\"\n   mkdocs build\n   echo \"Documentation built in ./site directory\"\n   ```\n2. Update any CI/CD pipelines (e.g., GitHub Actions):\n   ```yaml\n   name: docs\n   on: [push, pull_request]\n   jobs:\n     build:\n       runs-on: ubuntu-latest\n       steps:\n         - uses: actions/checkout@v4\n         - uses: actions/setup-python@v4\n           with:\n             python-version: '3.10'\n         - run: pip install -e \".[docs]\"\n         - run: mkdocs build --strict\n         # Add deployment steps if needed\n   ```\n3. Create a README.md in the docs/ directory with instructions:\n   - How to build docs locally\n   - How to add new documentation\n   - How to use mkdocstrings for API documentation\n4. Add a section in the documentation about the migration from Sphinx\n5. Test the complete documentation build process\n\nTesting approach:\n- Run the build script in a clean environment\n- Verify the documentation builds without errors\n- Check that all pages render correctly in the built site\n- Test any CI/CD integrations with a test commit",
          "status": "pending",
          "parentTaskId": 12
        }
      ]
    },
    {
      "id": 13,
      "title": "Implement Comprehensive Test Suites for Schema Validation and Tools",
      "description": "Create test suites for JSON schema validation, Python validator, and MATLAB tools according to the testing guidelines in .cursor/rules/testing.mdc.",
      "details": "This task involves implementing three distinct test suites:\n\n1. **JSON Schema Validation Tests** (`tests/schemas/`):\n   - Create tests that validate both valid and invalid JSON examples against the defined schemas\n   - Include edge cases for each schema field\n   - Organize tests by schema type with clear naming conventions\n   - Test all constraints defined in schemas (required fields, data types, ranges, etc.)\n\n2. **Python Validator Tests** (`tests/validator/`):\n   - Implement unit tests for the Python validator module\n   - Test validation functions with valid/invalid inputs\n   - Include tests for error handling and edge cases\n   - Mock any external dependencies\n   - Test performance with large inputs where applicable\n\n3. **MATLAB Tools Tests** (`tests/matlab/`):\n   - Use MATLAB's unit testing framework\n   - Create test fixtures for common test data\n   - Test all MATLAB utility functions and tools\n   - Verify correct handling of various input formats\n   - Test integration between MATLAB components\n\nEnsure all tests follow the conventions specified in `.cursor/rules/testing.mdc`. Add necessary test dependencies to the project configuration files (requirements-dev.txt for Python, etc.). Implement CI-friendly tests that can run in automated environments.\n\n**Git Workflow:**\n- Before starting, create a feature branch (e.g., `feature/13-implement-tests`)\n- After implementation and testing, create a PR targeting `main`\n- Add a comment tagging @neuromechanist for review, mentioning this task ID",
      "testStrategy": "Verification will involve:\n\n1. **Code Review**:\n   - Ensure test organization follows the specified directory structure\n   - Verify tests follow the guidelines in `.cursor/rules/testing.mdc`\n   - Check test coverage for all components\n\n2. **Test Execution**:\n   - All tests must pass when run with pytest (Python) and MATLAB's test runner\n   - Run `pytest tests/schemas/ tests/validator/ --cov` to verify Python test coverage (aim for >90%)\n   - Run MATLAB tests using `runtests('tests/matlab')` and verify all pass\n\n3. **Coverage Verification**:\n   - Generate coverage reports for Python tests\n   - Ensure all critical paths in the code are tested\n   - Verify edge cases and error conditions are covered\n\n4. **CI Integration**:\n   - Tests should run successfully in the CI pipeline\n   - Test dependencies should be properly specified in configuration files\n\nThe task is complete when all test suites are implemented, passing, and providing adequate coverage of the codebase according to the guidelines.",
      "status": "in-progress",
      "dependencies": [
        11
      ],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Set up test directory structure and test utilities",
          "description": "Create the foundational test infrastructure including directory structure, test utilities, and helper functions that will be used across all test suites.",
          "dependencies": [],
          "details": "1. Create the main test directories: `tests/schemas/`, `tests/validator/`, and `tests/matlab/`\n2. Set up test configuration files (pytest.ini, .coveragerc)\n3. Create shared test utilities:\n   - Implement a JSON file loader utility that handles errors gracefully\n   - Create test data generators for common test cases\n   - Implement assertion helpers for schema validation errors\n4. Set up test fixtures for reusable test data and mocks\n5. Configure test dependencies in requirements-dev.txt (pytest, pytest-cov, jsonschema, fastjsonschema)\n6. Create documentation for the test structure in tests/README.md\n7. Testing approach: Write unit tests for the utilities themselves to ensure they work correctly\n\n<info added on 2025-05-02T19:04:04.584Z>\n# Implementation Details\n\n## Directory Structure Setup\n```\nproject_root/\n├── tests/\n│   ├── __init__.py\n│   ├── conftest.py\n│   ├── schemas/\n│   │   └── __init__.py\n│   ├── validator/\n│   │   └── __init__.py\n│   └── matlab/\n│       └── __init__.py\n```\n\n## Configuration Files\n\n### pytest.ini\n```ini\n[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts = --cov=mdc_validator --cov-report=term-missing\n```\n\n### .coveragerc\n```ini\n[run]\nsource = mdc_validator\nomit = \n    */tests/*\n    */site-packages/*\n\n[report]\nexclude_lines =\n    pragma: no cover\n    def __repr__\n    raise NotImplementedError\n```\n\n## Test Utilities Implementation\n\n### JSON File Loader (tests/utils.py)\n```python\nimport json\nimport os\nfrom typing import Any, Dict, Optional\n\ndef load_json_file(filepath: str) -> Dict[str, Any]:\n    \"\"\"\n    Load and parse a JSON file with graceful error handling.\n    \n    Args:\n        filepath: Path to the JSON file\n        \n    Returns:\n        Parsed JSON content as dictionary\n        \n    Raises:\n        FileNotFoundError: If file doesn't exist\n        JSONDecodeError: If JSON is invalid\n    \"\"\"\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"JSON file not found: {filepath}\")\n        \n    try:\n        with open(filepath, 'r', encoding='utf-8') as f:\n            return json.load(f)\n    except json.JSONDecodeError as e:\n        raise json.JSONDecodeError(\n            f\"Invalid JSON in {filepath}: {str(e)}\", \n            e.doc, \n            e.pos\n        )\n```\n\n### Test Fixtures (conftest.py)\n```python\nimport pytest\nimport os\nimport json\nfrom pathlib import Path\n\n@pytest.fixture\ndef sample_schema_path():\n    \"\"\"Return path to test schemas directory\"\"\"\n    return Path(__file__).parent / \"schemas\" / \"samples\"\n\n@pytest.fixture\ndef load_test_schema():\n    \"\"\"Fixture to load a test schema file\"\"\"\n    def _load(filename):\n        schema_path = Path(__file__).parent / \"schemas\" / \"samples\" / filename\n        with open(schema_path, 'r', encoding='utf-8') as f:\n            return json.load(f)\n    return _load\n\n@pytest.fixture\ndef valid_minimal_schema():\n    \"\"\"Return a minimal valid schema for testing\"\"\"\n    return {\n        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\"type\": \"string\"},\n            \"value\": {\"type\": \"number\"}\n        },\n        \"required\": [\"name\"]\n    }\n```\n\n### Assertion Helpers (tests/utils.py)\n```python\ndef assert_validation_error(validator_func, data, expected_error_substring):\n    \"\"\"\n    Assert that validation fails with an error containing the expected substring.\n    \n    Args:\n        validator_func: Function that performs validation and raises exceptions\n        data: Data to validate\n        expected_error_substring: String expected to be in the error message\n    \"\"\"\n    try:\n        validator_func(data)\n        pytest.fail(f\"Expected validation error containing '{expected_error_substring}', but validation passed\")\n    except Exception as e:\n        error_message = str(e)\n        assert expected_error_substring in error_message, \\\n            f\"Expected error containing '{expected_error_substring}', got: '{error_message}'\"\n```\n\n## Test Data Generators\n```python\ndef generate_test_cases():\n    \"\"\"Generate common test cases for schema validation\"\"\"\n    return [\n        {\"name\": \"valid_simple\", \"data\": {\"name\": \"test\"}, \"should_pass\": True},\n        {\"name\": \"missing_required\", \"data\": {}, \"should_pass\": False},\n        {\"name\": \"wrong_type\", \"data\": {\"name\": 123}, \"should_pass\": False},\n        {\"name\": \"extra_property\", \"data\": {\"name\": \"test\", \"extra\": True}, \"should_pass\": True},\n    ]\n```\n</info added on 2025-05-02T19:04:04.584Z>",
          "status": "done",
          "parentTaskId": 13
        },
        {
          "id": 2,
          "title": "Implement JSON Schema validation test suite",
          "description": "Create comprehensive tests for validating JSON documents against the defined schemas, covering valid cases, invalid cases, and edge cases for each schema type.",
          "dependencies": [
            1
          ],
          "details": "1. For each schema type, create separate test modules with clear naming conventions\n2. Implement parameterized tests using pytest.mark.parametrize to test multiple data samples against each schema\n3. Create test data files:\n   - Valid examples that pass validation\n   - Invalid examples that fail in specific ways (missing required fields, wrong data types, out of range values)\n   - Edge cases (empty arrays, minimum/maximum values, etc.)\n4. Test all constraints defined in schemas:\n   - Required fields validation\n   - Data type validation\n   - Range constraints\n   - Pattern matching for strings\n   - Array length constraints\n5. Implement specific error message validation to ensure proper error reporting\n6. Add performance tests for large JSON documents using fastjsonschema for efficiency\n7. Testing approach: Run tests with pytest and verify that valid documents pass validation while invalid documents fail with the expected error messages\n\n<info added on 2025-05-02T19:06:15.863Z>\n## Implementation Plan (Iteration 1)\n\n### Directory Structure Setup\n```bash\nmkdir -p tests/schemas/examples/valid\nmkdir -p tests/schemas/examples/invalid\nmkdir -p tests/schemas/examples/edge_cases\n```\n\n### Example JSON Files\n\n**Valid Example (tests/schemas/examples/valid/minimal_valid.json):**\n```json\n{\n  \"sj_version\": \"1.0.0\",\n  \"schema_version\": \"1.0.0\",\n  \"description\": \"Minimal valid example\",\n  \"pipelineInfo\": {\n    \"name\": \"Test Pipeline\",\n    \"version\": \"0.1.0\"\n  },\n  \"processingSteps\": [\n    {\n      \"stepId\": \"step1\",\n      \"name\": \"First Step\",\n      \"description\": \"Initial processing step\",\n      \"software\": {\n        \"name\": \"test-software\",\n        \"version\": \"1.0.0\"\n      }\n    }\n  ]\n}\n```\n\n**Invalid Example (tests/schemas/examples/invalid/missing_required_top_level.json):**\n```json\n{\n  \"schema_version\": \"1.0.0\",\n  \"description\": \"Invalid example missing sj_version\",\n  \"pipelineInfo\": {\n    \"name\": \"Test Pipeline\",\n    \"version\": \"0.1.0\"\n  },\n  \"processingSteps\": [\n    {\n      \"stepId\": \"step1\",\n      \"name\": \"First Step\",\n      \"description\": \"Initial processing step\",\n      \"software\": {\n        \"name\": \"test-software\",\n        \"version\": \"1.0.0\"\n      }\n    }\n  ]\n}\n```\n\n### Test Implementation\n\n**conftest.py:**\n```python\nimport json\nimport os\nimport pytest\nfrom jsonschema import Draft7Validator\n\n@pytest.fixture\ndef load_json_example():\n    def _load(filename):\n        base_path = os.path.join(os.path.dirname(__file__), \"examples\")\n        with open(os.path.join(base_path, filename)) as f:\n            return json.load(f)\n    return _load\n\n@pytest.fixture\ndef validator():\n    # Load the schema from the package\n    from sciencejournal.schema import get_schema\n    schema = get_schema()\n    return Draft7Validator(schema)\n```\n\n**tests/schemas/test_schema_validation.py:**\n```python\nimport pytest\nimport jsonschema\n\ndef test_minimal_valid(validator, load_json_example):\n    \"\"\"Test that a minimal valid document passes validation.\"\"\"\n    data = load_json_example(\"valid/minimal_valid.json\")\n    validator.validate(data)  # Should not raise an exception\n\ndef test_missing_required_top_level(validator, load_json_example):\n    \"\"\"Test that missing a required top-level field fails validation.\"\"\"\n    data = load_json_example(\"invalid/missing_required_top_level.json\")\n    with pytest.raises(jsonschema.ValidationError) as excinfo:\n        validator.validate(data)\n    assert \"sj_version\" in str(excinfo.value)  # Verify error mentions missing field\n\n@pytest.mark.parametrize(\"field\", [\"schema_version\", \"description\", \"pipelineInfo\", \"processingSteps\"])\ndef test_required_fields(validator, load_json_example, field):\n    \"\"\"Parametrized test for all required top-level fields.\"\"\"\n    data = load_json_example(\"valid/minimal_valid.json\")\n    data.pop(field)  # Remove the field being tested\n    with pytest.raises(jsonschema.ValidationError):\n        validator.validate(data)\n```\n\n### Performance Testing\n\n```python\ndef test_large_document_performance(validator, benchmark):\n    \"\"\"Test validation performance with a large document.\"\"\"\n    # Generate a large document with many processing steps\n    large_doc = {\n        \"sj_version\": \"1.0.0\",\n        \"schema_version\": \"1.0.0\",\n        \"description\": \"Large test document\",\n        \"pipelineInfo\": {\"name\": \"Test\", \"version\": \"1.0\"},\n        \"processingSteps\": [\n            {\n                \"stepId\": f\"step{i}\",\n                \"name\": f\"Step {i}\",\n                \"description\": f\"Description {i}\",\n                \"software\": {\"name\": \"test\", \"version\": \"1.0\"}\n            } for i in range(1000)  # 1000 processing steps\n        ]\n    }\n    \n    # Benchmark validation time\n    def validate_large():\n        validator.validate(large_doc)\n    \n    benchmark(validate_large)\n    # Assert benchmark result is under acceptable threshold (e.g., 500ms)\n    # This will be automatically checked by pytest-benchmark\n```\n</info added on 2025-05-02T19:06:15.863Z>\n\n<info added on 2025-05-02T19:16:46.028Z>\n## Implementation Plan (Iteration 2)\n\n### Additional Invalid Test Examples\n\n**tests/schemas/examples/invalid/wrong_type.json:**\n```json\n{\n  \"sj_version\": 1.0,\n  \"schema_version\": \"1.0.0\",\n  \"description\": \"Invalid example with wrong type for sj_version\",\n  \"pipelineInfo\": {\n    \"name\": \"Test Pipeline\",\n    \"version\": \"0.1.0\"\n  },\n  \"processingSteps\": [\n    {\n      \"stepId\": \"step1\",\n      \"name\": \"First Step\",\n      \"description\": \"Initial processing step\",\n      \"software\": {\n        \"name\": \"test-software\",\n        \"version\": \"1.0.0\"\n      }\n    }\n  ]\n}\n```\n\n**tests/schemas/examples/invalid/bad_pattern.json:**\n```json\n{\n  \"sj_version\": \"0.1\",\n  \"schema_version\": \"1.0.0\",\n  \"description\": \"Invalid example with sj_version not matching pattern\",\n  \"pipelineInfo\": {\n    \"name\": \"Test Pipeline\",\n    \"version\": \"0.1.0\"\n  },\n  \"processingSteps\": [\n    {\n      \"stepId\": \"step1\",\n      \"name\": \"First Step\",\n      \"description\": \"Initial processing step\",\n      \"software\": {\n        \"name\": \"test-software\",\n        \"version\": \"1.0.0\"\n      }\n    }\n  ]\n}\n```\n\n**tests/schemas/examples/invalid/processing_steps_empty.json:**\n```json\n{\n  \"sj_version\": \"1.0.0\",\n  \"schema_version\": \"1.0.0\",\n  \"description\": \"Invalid example with empty processingSteps array\",\n  \"pipelineInfo\": {\n    \"name\": \"Test Pipeline\",\n    \"version\": \"0.1.0\"\n  },\n  \"processingSteps\": []\n}\n```\n\n**tests/schemas/examples/invalid/step_missing_required.json:**\n```json\n{\n  \"sj_version\": \"1.0.0\",\n  \"schema_version\": \"1.0.0\",\n  \"description\": \"Invalid example with processing step missing required field\",\n  \"pipelineInfo\": {\n    \"name\": \"Test Pipeline\",\n    \"version\": \"0.1.0\"\n  },\n  \"processingSteps\": [\n    {\n      \"stepId\": \"step1\",\n      \"description\": \"Step missing name field\",\n      \"software\": {\n        \"name\": \"test-software\",\n        \"version\": \"1.0.0\"\n      }\n    }\n  ]\n}\n```\n\n### Enhanced Test Implementation\n\n```python\nimport pytest\nimport jsonschema\nimport os\nimport json\n\n@pytest.mark.parametrize(\"filename,expected_valid\", [\n    (\"valid/minimal_valid.json\", True),\n    (\"invalid/missing_required_top_level.json\", False),\n    (\"invalid/wrong_type.json\", False),\n    (\"invalid/bad_pattern.json\", False),\n    (\"invalid/processing_steps_empty.json\", False),\n    (\"invalid/step_missing_required.json\", False),\n])\ndef test_schema_validation(validator, load_json_example, filename, expected_valid):\n    \"\"\"Test schema validation with various examples.\"\"\"\n    data = load_json_example(filename)\n    \n    if expected_valid:\n        validator.validate(data)  # Should not raise an exception\n    else:\n        with pytest.raises(jsonschema.ValidationError):\n            validator.validate(data)\n\n@pytest.mark.parametrize(\"filename,error_pattern\", [\n    (\"invalid/missing_required_top_level.json\", \"'sj_version' is a required property\"),\n    (\"invalid/wrong_type.json\", \"is not of type 'string'\"),\n    (\"invalid/bad_pattern.json\", \"does not match pattern\"),\n    (\"invalid/processing_steps_empty.json\", \"[] is too short\"),\n    (\"invalid/step_missing_required.json\", \"'name' is a required property\"),\n])\ndef test_specific_validation_errors(validator, load_json_example, filename, error_pattern):\n    \"\"\"Test that specific validation errors are raised with the expected message.\"\"\"\n    data = load_json_example(filename)\n    \n    with pytest.raises(jsonschema.ValidationError) as excinfo:\n        validator.validate(data)\n    \n    assert error_pattern in str(excinfo.value)\n\ndef test_edge_cases_with_fastjsonschema():\n    \"\"\"Test validation with fastjsonschema for performance comparison.\"\"\"\n    try:\n        import fastjsonschema\n    except ImportError:\n        pytest.skip(\"fastjsonschema not installed\")\n    \n    from sciencejournal.schema import get_schema\n    schema = get_schema()\n    \n    # Compile schema for faster validation\n    validate = fastjsonschema.compile(schema)\n    \n    # Test with valid data\n    base_path = os.path.join(os.path.dirname(__file__), \"examples\", \"valid\")\n    with open(os.path.join(base_path, \"minimal_valid.json\")) as f:\n        valid_data = json.load(f)\n    \n    # Should not raise an exception\n    validate(valid_data)\n    \n    # Test with invalid data\n    base_path = os.path.join(os.path.dirname(__file__), \"examples\", \"invalid\")\n    with open(os.path.join(base_path, \"missing_required_top_level.json\")) as f:\n        invalid_data = json.load(f)\n    \n    # Should raise an exception\n    with pytest.raises(fastjsonschema.JsonSchemaException):\n        validate(invalid_data)\n```\n\n### Edge Case Examples\n\n**tests/schemas/examples/edge_cases/max_length_description.json:**\n```json\n{\n  \"sj_version\": \"1.0.0\",\n  \"schema_version\": \"1.0.0\",\n  \"description\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\",\n  \"pipelineInfo\": {\n    \"name\": \"Test Pipeline\",\n    \"version\": \"0.1.0\"\n  },\n  \"processingSteps\": [\n    {\n      \"stepId\": \"step1\",\n      \"name\": \"First Step\",\n      \"description\": \"Initial processing step\",\n      \"software\": {\n        \"name\": \"test-software\",\n        \"version\": \"1.0.0\"\n      }\n    }\n  ]\n}\n```\n</info added on 2025-05-02T19:16:46.028Z>",
          "status": "done",
          "parentTaskId": 13
        },
        {
          "id": 3,
          "title": "Implement Python validator unit test suite",
          "description": "Create comprehensive unit tests for the Python validator module, focusing on function-level testing, error handling, and edge cases.",
          "dependencies": [
            1
          ],
          "details": "1. Organize tests by validator module/function with clear test class and method names\n2. Implement unit tests for each validation function using the Arrange-Act-Assert pattern:\n   - Test with valid inputs to ensure they pass\n   - Test with invalid inputs to verify proper error handling\n   - Test edge cases (empty inputs, boundary values)\n3. Use mocking (pytest-mock or unittest.mock) to isolate validator functions from external dependencies\n4. Test error handling:\n   - Verify appropriate exceptions are raised\n   - Check error messages for clarity and specificity\n5. Implement integration tests that verify the validator works end-to-end\n6. Add performance tests for validation of large datasets\n7. Use coverage reporting to ensure all code paths are tested\n8. Testing approach: Use pytest fixtures for test data setup, run with pytest, and verify function behavior matches specifications\n\n<info added on 2025-05-02T19:18:17.256Z>\nHere's additional implementation information for the Python validator test suite:\n\n```\n9. Test Implementation Details:\n   - Use parameterized tests to efficiently test multiple input variations with the same test logic\n   - Create test fixtures that provide sample valid/invalid JSON data of varying complexity\n   - Implement property-based testing using Hypothesis library for more thorough validation testing\n   - Test validation schema customization options (if supported)\n\n10. Test Data Organization:\n    - Create a dedicated test_data/ directory with subdirectories for:\n      - valid_inputs/: Contains valid JSON files of varying complexity\n      - invalid_inputs/: Contains invalid JSON files with specific validation errors\n      - edge_cases/: Contains boundary condition test files\n\n11. Specific Test Cases to Implement:\n    - test_schema_validation(): Verify schema structure validation works correctly\n    - test_data_type_validation(): Ensure proper type checking for all fields\n    - test_required_field_validation(): Verify required fields are enforced\n    - test_optional_field_handling(): Check optional fields are properly handled\n    - test_nested_object_validation(): Test validation of complex nested structures\n    - test_array_validation(): Verify array validation including min/max items\n    - test_custom_format_validators(): Test any custom format validators\n\n12. CI Integration:\n    - Configure pytest.ini with appropriate test markers and settings\n    - Set up test reporting compatible with CI environment\n    - Implement test coverage thresholds (aim for >90% coverage)\n```\n</info added on 2025-05-02T19:18:17.256Z>",
          "status": "done",
          "parentTaskId": 13
        },
        {
          "id": 4,
          "title": "Implement MATLAB tools test suite",
          "description": "Create comprehensive tests for MATLAB utility functions and tools using MATLAB's unit testing framework, ensuring all components work correctly individually and together.",
          "dependencies": [
            1
          ],
          "details": "1. Set up MATLAB test classes using the matlab.unittest framework\n2. Create test fixtures for common test data in .mat format\n3. Implement tests for each MATLAB utility function:\n   - Basic functionality tests with valid inputs\n   - Error handling tests with invalid inputs\n   - Edge case tests\n4. Test integration between MATLAB components:\n   - Data flow between functions\n   - End-to-end processing pipelines\n5. For JSON schema validation in MATLAB:\n   - Test MATLAB-Python integration if using Python validators\n   - Or test custom MATLAB validation functions\n6. Implement performance tests for computationally intensive operations\n7. Create test runner scripts that can be executed from command line or CI\n8. Testing approach: Use MATLAB's verifyEqual, verifyTrue, and verifyError methods to assert expected outcomes",
          "status": "pending",
          "parentTaskId": 13
        },
        {
          "id": 5,
          "title": "Integrate tests with CI pipeline and documentation",
          "description": "Configure continuous integration for automated test execution, create comprehensive test documentation, and ensure all tests follow project conventions.",
          "dependencies": [
            2,
            3,
            4
          ],
          "details": "1. Configure CI workflow in GitHub Actions or similar platform:\n   - Set up Python environment for schema and validator tests\n   - Configure MATLAB environment for MATLAB tests\n   - Set up test reporting and coverage analysis\n2. Create comprehensive test documentation:\n   - Document test strategy and approach\n   - Provide examples of how to run tests locally\n   - Document test data and expected outcomes\n3. Ensure all tests follow conventions in .cursor/rules/testing.mdc:\n   - Review and update naming conventions\n   - Check formatting and style consistency\n   - Verify documentation standards\n4. Implement test summary reporting:\n   - Generate HTML or XML test reports\n   - Configure coverage reporting\n5. Create a PR template with test verification checklist\n6. Testing approach: Manually verify that all tests run successfully in the CI environment and produce expected reports",
          "status": "pending",
          "parentTaskId": 13
        }
      ]
    },
    {
      "id": 14,
      "title": "Set up GitHub Actions CI/CD Workflows",
      "description": "Implement GitHub Actions workflows for testing and documentation deployment based on the specifications in `.cursor/rules/ci-cd.mdc`.",
      "details": "Create two GitHub Actions workflow files in the `.github/workflows/` directory:\n\n1. `test.yml`:\n   - Configure to run on push events and pull requests\n   - Include the following jobs:\n     - Linting (if applicable for the project)\n     - Python testing using pytest\n     - MATLAB testing (if feasible, research GitHub Actions support for MATLAB)\n     - Schema validation for project data files\n   - Set up appropriate environment with necessary dependencies\n   - Configure test matrix if needed for multiple Python/MATLAB versions\n   - Ensure proper caching of dependencies to speed up workflow runs\n\n2. `deploy-docs.yml`:\n   - Configure to run only on push events to the main branch\n   - Set up job to build the MkDocs documentation\n   - Configure GitHub Pages deployment\n   - Ensure proper permissions for the GitHub token\n   - Set up caching for faster builds\n\nReference the `.cursor/rules/ci-cd.mdc` file for specific requirements and configurations. Ensure both workflows use appropriate GitHub Actions marketplace actions where possible rather than custom scripts. Document any environment variables or secrets that need to be configured in the repository settings.",
      "testStrategy": "To verify correct implementation:\n\n1. For `test.yml`:\n   - Push a commit with passing tests to verify the workflow runs successfully\n   - Push a commit with failing tests to verify the workflow correctly identifies failures\n   - Create a pull request to ensure the workflow triggers on PR events\n   - Check that all specified jobs (linting, Python tests, MATLAB tests if applicable, schema validation) are running\n   - Verify that the workflow logs show proper execution of each step\n\n2. For `deploy-docs.yml`:\n   - Push a change to the main branch that includes documentation updates\n   - Verify that the workflow runs and successfully builds the documentation\n   - Check that the documentation is properly deployed to GitHub Pages\n   - Verify the deployed site is accessible and displays the updated content\n   - Test that the workflow does not run on branches other than main\n\nAdditionally, review the workflow files to ensure they follow best practices for GitHub Actions, including proper use of actions, caching, and error handling.",
      "status": "pending",
      "dependencies": [
        12,
        13
      ],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Create basic test.yml workflow structure",
          "description": "Set up the foundational structure for the test.yml workflow file with proper event triggers and job organization.",
          "dependencies": [],
          "details": "1. Create the `.github/workflows/` directory if it doesn't exist\n2. Create a new file named `test.yml` in this directory\n3. Configure the workflow to run on push events and pull requests\n4. Set up the basic structure with name, triggers, and job placeholders\n5. Define the main test job with ubuntu-latest runner\n6. Add checkout action as the first step\n7. Configure proper permissions for the workflow\n8. Test the workflow by pushing the basic structure to verify GitHub Actions recognizes it\n9. Use the following template as a starting point:\n```yaml\nname: Tests\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      # More steps will be added in subsequent tasks\n```",
          "status": "pending",
          "parentTaskId": 14
        },
        {
          "id": 2,
          "title": "Implement Python testing with pytest in test.yml",
          "description": "Configure the test.yml workflow to set up Python environment, install dependencies, and run pytest with proper caching.",
          "dependencies": [
            1
          ],
          "details": "1. Add steps to set up Python environment using actions/setup-python@v4\n2. Implement matrix strategy to test across multiple Python versions (e.g., 3.8, 3.9, 3.10)\n3. Configure dependency caching to speed up workflow runs\n4. Add steps to install project dependencies from requirements.txt or pyproject.toml\n5. Add step to run pytest with appropriate flags\n6. Configure test coverage reporting\n7. Add the following code to the test job in test.yml:\n```yaml\n    strategy:\n      matrix:\n        python-version: ['3.8', '3.9', '3.10']\n    steps:\n      # ... existing checkout step ...\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip'\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi\n          pip install pytest pytest-cov\n      - name: Run tests\n        run: pytest --cov=./ --cov-report=xml\n```",
          "status": "pending",
          "parentTaskId": 14
        },
        {
          "id": 3,
          "title": "Add linting and schema validation to test.yml",
          "description": "Enhance the test workflow with linting checks and schema validation for project data files.",
          "dependencies": [
            2
          ],
          "details": "1. Add a separate job for linting in the test.yml workflow\n2. Configure linting tools based on project requirements (e.g., flake8, pylint, or black)\n3. Implement schema validation for project data files\n4. Ensure proper dependency installation for validation tools\n5. Configure appropriate exit codes to fail the workflow on validation errors\n6. Add the following code to test.yml:\n```yaml\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n          cache: 'pip'\n      - name: Install linting dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install flake8 black isort\n      - name: Run linters\n        run: |\n          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n          black --check .\n          isort --check .\n          \n  validate-schema:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - name: Install validation dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install jsonschema pyyaml\n      - name: Validate data files\n        run: |\n          # Add custom script to validate data files against schemas\n          python scripts/validate_schemas.py\n```\n7. Create a simple schema validation script if one doesn't exist",
          "status": "pending",
          "parentTaskId": 14
        },
        {
          "id": 4,
          "title": "Configure MATLAB testing in test.yml",
          "description": "Research and implement GitHub Actions support for MATLAB testing within the test workflow.",
          "dependencies": [
            1
          ],
          "details": "1. Research the latest GitHub Actions marketplace actions for MATLAB support\n2. Add a dedicated job for MATLAB testing in test.yml\n3. Use the mathworks-actions/setup-matlab action to configure the MATLAB environment\n4. Set up appropriate licensing for MATLAB in GitHub Actions\n5. Configure the test script execution\n6. Add caching for MATLAB where possible\n7. Add the following code to test.yml:\n```yaml\n  matlab-test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up MATLAB\n        uses: matlab-actions/setup-matlab@v1\n      - name: Run MATLAB Tests\n        uses: matlab-actions/run-tests@v1\n        with:\n          source-folder: src\n          select-by-folder: test\n          test-results-junit: test-results/results.xml\n          code-coverage-cobertura: code-coverage/coverage.xml\n      - name: Upload test results\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: matlab-test-results\n          path: test-results\n      - name: Upload code coverage\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: matlab-code-coverage\n          path: code-coverage\n```\n8. Document any required repository secrets for MATLAB licensing",
          "status": "pending",
          "parentTaskId": 14
        },
        {
          "id": 5,
          "title": "Create deploy-docs.yml workflow for MkDocs",
          "description": "Implement a separate workflow file for building and deploying MkDocs documentation to GitHub Pages.",
          "dependencies": [],
          "details": "1. Create a new file named `deploy-docs.yml` in the `.github/workflows/` directory\n2. Configure the workflow to run only on push events to the main branch\n3. Set up a job to build the MkDocs documentation\n4. Configure GitHub Pages deployment with appropriate permissions\n5. Implement caching for faster builds\n6. Add the following code to deploy-docs.yml:\n```yaml\nname: Deploy Documentation\n\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: write\n\njobs:\n  deploy-docs:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 0\n      \n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n          cache: 'pip'\n      \n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install mkdocs mkdocs-material\n          if [ -f docs/requirements.txt ]; then pip install -r docs/requirements.txt; fi\n      \n      - name: Build documentation\n        run: mkdocs build\n      \n      - name: Deploy to GitHub Pages\n        uses: JamesIves/github-pages-deploy-action@v4\n        with:\n          folder: site\n          clean: true\n```\n7. Test the workflow by making a small change to documentation and pushing to main\n8. Verify the documentation is properly deployed to GitHub Pages\n9. Update repository settings to use the gh-pages branch for GitHub Pages if needed",
          "status": "pending",
          "parentTaskId": 14
        }
      ]
    }
  ],
  "metadata": {
    "projectName": "signalJourney Implementation",
    "totalTasks": 10,
    "sourceFile": "scripts/prd.txt",
    "generatedAt": "2023-11-15"
  }
}